<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<!-- Inform modern browsers that this page supports both dark and light color schemes,
  and the page author prefers light. --><meta name="color-scheme" content="dark light">
<script>
  // If `prefers-color-scheme` is not supported, fall back to light mode.
  // i.e. In this case, inject the `light` CSS before the others, with
  // no media filter so that it will be downloaded with highest priority.
  if (window.matchMedia("(prefers-color-scheme: dark)").media === "not all") {
    document.documentElement.style.display = "none";
    document.head.insertAdjacentHTML(
      "beforeend",
      "<link id=\"css\" rel=\"stylesheet\" href=\"https://bootswatch.com/3/flatly/bootstrap.css\" onload=\"document.documentElement.style.display = ''\">"
    );
  }
</script><title>Approximate Inference for Multinomial Logit Models with Random Effects • mclogit</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Approximate Inference for Multinomial Logit Models with Random Effects">
<meta property="og:description" content="mclogit">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Flatly Theme - Light  --><link id="css-light" rel="stylesheet" href="https://bootswatch.com/3/flatly/bootstrap.css" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
<!-- Darkly Theme - Dark --><link id="css-dark" rel="stylesheet" href="https://bootswatch.com/3/darkly/bootstrap.css" media="(prefers-color-scheme: dark)">
<!-- preferably CSS --><link rel="stylesheet" href="../preferably.css">
<link id="css-code-light" rel="stylesheet" href="../code-color-scheme-light.css" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
<link id="css-code-dark" rel="stylesheet" href="../code-color-scheme-dark.css" media="(prefers-color-scheme: dark)">
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">mclogit</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.9.8</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="divider">
    </li>
<li class="dropdown-header">The statistical models</li>
    <li>
      <a href="../articles/conditional-logit.html">Conditional logit models</a>
    </li>
    <li>
      <a href="../articles/baseline-logit.html">Baseline-category logit models</a>
    </li>
    <li>
      <a href="../articles/baseline-and-conditional-logit.html">The relation between baseline logit and conditional logit models</a>
    </li>
    <li>
      <a href="../articles/random-effects.html">Random effects in baseline logit models and conditional logit models</a>
    </li>
    <li class="divider">
    </li>
<li class="dropdown-header">Technical aspects of model fitting</li>
    <li>
      <a href="../articles/fitting-mclogit.html">The IWLS algorithm used to fit conditional logit models</a>
    </li>
    <li>
      <a href="../articles/approximations.html">Approximate Inference for Multinomial Logit Models with Random Effects</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/melff/mclogit/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
        
        


      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Approximate Inference for Multinomial Logit
Models with Random Effects</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/melff/mclogit/blob/HEAD/../vignettes/approximations.Rmd" class="external-link"><code>../vignettes/approximations.Rmd</code></a></small>
      <div class="hidden name"><code>approximations.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="the-problem">The problem<a class="anchor" aria-label="anchor" href="#the-problem"></a>
</h2>
<p>A crucial problem for inference about non-linear models with random
effects is that the likelihood function for such models involves
integrals for which no analytical solution exists.</p>
<p>For given values <span class="math inline">\(\boldsymbol{b}\)</span>
of the random effects the likelihood function of a conditional logit
model (and therefore also of a baseline-logit model) can be written in
the form</p>
<p><span class="math display">\[
\mathcal{L}_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})
=
\exp\left(\ell_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})\right)
=\exp
\left(
\ell(\boldsymbol{y}|\boldsymbol{b};\boldsymbol{\alpha})
-\frac12\ln\det(\boldsymbol{\Sigma})
-\frac12\boldsymbol{b}'\boldsymbol{\Sigma}^{-1}\boldsymbol{b}
\right)
\]</span></p>
<p>However, this “complete data” likelihood function cannot be used for
inference, because it depends on the unobserved random effects. To
arrive at a likelihood function that depends only on observed data, one
needs to used the following integrated likelihood function:</p>
<p><span class="math display">\[
\mathcal{L}_{\text{obs}}(\boldsymbol{y})
=
\int
\exp\left(\ell_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})\right)
\partial \boldsymbol{b}
=
\int
\exp
\left(
\ell(\boldsymbol{y}|\boldsymbol{b};\boldsymbol{\alpha})
-\frac12\ln\det(\boldsymbol{\Sigma})
-\frac12\boldsymbol{b}'\boldsymbol{\Sigma}^{-1}\boldsymbol{b}
\right)
\partial \boldsymbol{b}
\]</span></p>
<p>In general, this integral cannot be “solved”, i.e. eliminated from
the formula by analytic means (it is “analytically untractable”).
Instead, one will compute it either using numeric techniques (e.g. using
numerical quadrature) or approximate it using analytical techniques.
Unless there is only a single level of random effects numerical
quadrature can become computationally be demanding, that is, the
computation of the (log-)likelihood function and its derivatives can
take a lot of time even on modern, state-of-the-art computer hardware.
Yet approximations based on analytical techniques hand may lead to
biased estimates in particular in samples where the number of
observations relative to the number of random offects is small, but at
least they are much easier to compute and sometimes making inference
possible after all.</p>
<p>The package “mclogit” supports to kinds of analytical approximations,
the Laplace approximation and what one may call the Solomon-Cox
appoximation. Both approximations are based on a quadratic expansion of
the integrand so that the thus modified integral does have a closed-form
solution, i.e. is analytically tractable.</p>
</div>
<div class="section level2">
<h2 id="the-laplace-approximation-and-pql">The Laplace approximation and PQL<a class="anchor" aria-label="anchor" href="#the-laplace-approximation-and-pql"></a>
</h2>
<div class="section level3">
<h3 id="laplace-approximation">Laplace approximation<a class="anchor" aria-label="anchor" href="#laplace-approximation"></a>
</h3>
<p>The (first-order) Laplace approximation is based on the quadratic
expansion the logarithm of the integrand, the complete-data
log-likelihood</p>
<p><span class="math display">\[
\ell_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})\approx
\ell(\boldsymbol{y}|\tilde{\boldsymbol{b}};\boldsymbol{\alpha})
-
\frac12
(\boldsymbol{b}-\tilde{\boldsymbol{b}})'
\tilde{\boldsymbol{H}}
(\boldsymbol{b}-\tilde{\boldsymbol{b}})
-\frac12\ln\det(\boldsymbol{\Sigma})
-\frac12(\boldsymbol{b}-\tilde{\boldsymbol{b}})'\boldsymbol{\Sigma}^{-1}(\boldsymbol{b}-\tilde{\boldsymbol{b}})
\]</span></p>
<p>where <span class="math inline">\(\tilde{\boldsymbol{b}}\)</span> is
the solution to</p>
<p><span class="math display">\[
\frac{\partial\ell_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})}{\partial\boldsymbol{b}}
= 0
\]</span></p>
<p>and <span class="math inline">\(\tilde{\boldsymbol{H}}=\boldsymbol{H}(\tilde{\boldsymbol{b}})\)</span>
is the value of the negative Hessian with respect to <span class="math inline">\(\boldsymbol{b}\)</span></p>
<p><span class="math display">\[
\boldsymbol{H}(\boldsymbol{b})=-\frac{\partial^2\ell(\boldsymbol{y}|\boldsymbol{b};\boldsymbol{\alpha})}{\partial\boldsymbol{b}\partial\boldsymbol{b}'}
\]</span></p>
<p>for <span class="math inline">\(\boldsymbol{b}=\tilde{\boldsymbol{b}}\)</span>.</p>
<p>Since this quadratic expansion—let us call it <span class="math inline">\(\ell^*_{\text{Lapl}}(\boldsymbol{y},\boldsymbol{b})\)</span>—is
a (multivariate) quadratic function of <span class="math inline">\(\boldsymbol{b}\)</span>, the integral of its
exponential does have a closed-form solution (the relevant formula can
be found in <span class="citation">Harville (1997)</span>).</p>
<p>For purposes of estimation, the resulting approximate log-likelihood
is more useful:</p>
<p><span class="math display">\[
\ell^*_{\text{Lapl}}
=
\ln\int \exp(\ell_{\text{Lapl}}(\boldsymbol{y},\boldsymbol{b}))
\partial\boldsymbol{b}
=
\ell(\boldsymbol{y}|\tilde{\boldsymbol{b}};\boldsymbol{\alpha})
-
\frac12\tilde{\boldsymbol{b}}'\boldsymbol{\Sigma}^{-1}\tilde{\boldsymbol{b}}
-
\frac12\ln\det(\boldsymbol{\Sigma})
-
\frac12\ln\det\left(\tilde{\boldsymbol{H}}+\boldsymbol{\Sigma}^{-1}\right).
\]</span></p>
</div>
<div class="section level3">
<h3 id="penalized-quasi-likelihood-pql">Penalized quasi-likelihood (PQL)<a class="anchor" aria-label="anchor" href="#penalized-quasi-likelihood-pql"></a>
</h3>
<p>If one disregards the dependence of <span class="math inline">\(\tilde{\boldsymbol{H}}\)</span> on <span class="math inline">\(\boldsymbol{\alpha}\)</span> and <span class="math inline">\(\boldsymbol{b}\)</span>, then <span class="math inline">\(\tilde{\boldsymbol{b}}\)</span> maximizes not only
<span class="math inline">\(\ell_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})\)</span>
but also <span class="math inline">\(\ell^*_{\text{Lapl}}\)</span>. This
motivates the following IWLS/Fisher scoring equations for <span class="math inline">\(\hat{\boldsymbol{\alpha}}\)</span> and <span class="math inline">\(\tilde{\boldsymbol{b}}\)</span> (see <span class="citation">Breslow and Clayton (1993)</span> and <a href="fitting-mclogit.html">this page</a>):</p>
<p><span class="math display">\[
\begin{aligned}
\begin{bmatrix}
\boldsymbol{X}'\boldsymbol{W}\boldsymbol{X} &amp;
\boldsymbol{X}'\boldsymbol{W}\boldsymbol{Z} \\
\boldsymbol{Z}'\boldsymbol{W}\boldsymbol{X} &amp;
\boldsymbol{Z}'\boldsymbol{W}\boldsymbol{Z} +
\boldsymbol{\Sigma}^{-1}\\
\end{bmatrix}
\begin{bmatrix}
\hat{\boldsymbol{\alpha}}\\
\tilde{\boldsymbol{b}}\\
\end{bmatrix}
=
\begin{bmatrix}
\boldsymbol{X}'\boldsymbol{W}\boldsymbol{y}^*\\
\boldsymbol{Z}'\boldsymbol{W}\boldsymbol{y}^*
\end{bmatrix}
\end{aligned}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\boldsymbol{y}^* =  \boldsymbol{X}\boldsymbol{\alpha} +
\boldsymbol{Z}\boldsymbol{b} +
\boldsymbol{W}^{-}(\boldsymbol{y}-\boldsymbol{\pi})
\]</span></p>
<p>is the IWLS “working dependend variable” with <span class="math inline">\(\boldsymbol{\alpha}\)</span>, <span class="math inline">\(\boldsymbol{b}\)</span>, <span class="math inline">\(\boldsymbol{W}\)</span>, and <span class="math inline">\(\boldsymbol{\pi}\)</span> computed in an earlier
iteration.</p>
<p>Substitutions lead to the equations:</p>
<p><span class="math display">\[
(\boldsymbol{X}\boldsymbol{V}^-\boldsymbol{X})\hat{\boldsymbol{\alpha}}
=
\boldsymbol{X}\boldsymbol{V}^-\boldsymbol{y}^*
\]</span></p>
<p>and</p>
<p><span class="math display">\[
(\boldsymbol{Z}'\boldsymbol{W}\boldsymbol{Z} +
\boldsymbol{\Sigma}^{-1})\boldsymbol{b} =
\boldsymbol{Z}'\boldsymbol{W}(\boldsymbol{y}^*-\boldsymbol{X}\boldsymbol{\alpha})
\]</span></p>
<p>which can be solved to compute <span class="math inline">\(\hat{\boldsymbol{\alpha}}\)</span> and <span class="math inline">\(\tilde{\boldsymbol{b}}\)</span> (for given <span class="math inline">\(\boldsymbol{\Sigma}\)</span>)</p>
<p>Here</p>
<p><span class="math display">\[
\boldsymbol{V} =
\boldsymbol{W}^-+\boldsymbol{Z}\boldsymbol{\Sigma}\boldsymbol{Z}'
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\boldsymbol{V}^- = \boldsymbol{W}-
\boldsymbol{W}\boldsymbol{Z}'\left(\boldsymbol{Z}'\boldsymbol{W}\boldsymbol{Z}+\boldsymbol{\Sigma}^{-1}\right)^{-1}\boldsymbol{Z}\boldsymbol{W}
\]</span></p>
<p>Following <span class="citation">Breslow and Clayton (1993)</span>
the variance parameters in <span class="math inline">\(\boldsymbol{\Sigma}\)</span> are estimated by
minimizing</p>
<p><span class="math display">\[
q_1 =
\det(\boldsymbol{V})+(\boldsymbol{y}^*-\boldsymbol{X}\boldsymbol{\alpha})\boldsymbol{V}^-(\boldsymbol{y}^*-\boldsymbol{X}\boldsymbol{\alpha})
\]</span></p>
<p>or the “REML” variant:</p>
<p><span class="math display">\[
q_2 =
\det(\boldsymbol{V})+(\boldsymbol{y}^*-\boldsymbol{X}\boldsymbol{\alpha})\boldsymbol{V}^-(\boldsymbol{y}^*-\boldsymbol{X}\boldsymbol{\alpha})+\det(\boldsymbol{X}'\boldsymbol{V}^{-}\boldsymbol{X})
\]</span></p>
<p>This motivates the following algorithm, which is strongly inspired by
the <code><a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html" class="external-link">glmmPQL()</a></code> function in Brian Ripley’s <em>R</em> package
<a href="https://cran.r-project.org/package=MASS" class="external-link">MASS</a> <span class="citation">(Venables and Ripley 2002)</span>:</p>
<ol style="list-style-type: decimal">
<li>Create some suitable starting values for <span class="math inline">\(\boldsymbol{\pi}\)</span>, <span class="math inline">\(\boldsymbol{W}\)</span>, and <span class="math inline">\(\boldsymbol{y}^*\)</span>
</li>
<li>Construct the “working dependent variable” <span class="math inline">\(\boldsymbol{y}^*\)</span>
</li>
<li>Minimize <span class="math inline">\(q_1\)</span> (quasi-ML) or
<span class="math inline">\(q_2\)</span> (quasi-REML) iteratively (inner
loop), to obtain an estimate of <span class="math inline">\(\boldsymbol{\Sigma}\)</span>
</li>
<li>Obtain <span class="math inline">\(hat{\boldsymbol{\alpha}}\)</span>
and <span class="math inline">\(\tilde{\boldsymbol{b}}\)</span> based on
the current estimate of <span class="math inline">\(\boldsymbol{\Sigma}\)</span>
</li>
<li>Compute updated <span class="math inline">\(\boldsymbol{\eta}=\boldsymbol{X}\boldsymbol{\alpha}
+
\boldsymbol{Z}\boldsymbol{b}\)</span>, <span class="math inline">\(\boldsymbol{\pi}\)</span>, <span class="math inline">\(\boldsymbol{W}\)</span>.</li>
<li>If the change in <span class="math inline">\(\boldsymbol{\eta}\)</span> is smaller than a given
tolerance criterion stop the algorighm and declare it as converged.
Otherwise go back to step 2 with the updated values of <span class="math inline">\(\hat{\boldsymbol{\alpha}}\)</span> and <span class="math inline">\(\tilde{\boldsymbol{b}}\)</span>.</li>
</ol>
<p>This algorithm is a modification of the <a href="fitting-mclogit.html">IWLS</a> algorithm used to fit conditional
logit models without random effects. Instead of just solving a linear
requatoin in step 3, it estimates a weighted linear mixed-effects model.
In contrast to <code><a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html" class="external-link">glmmPQL()</a></code> it does not use the
<code>lme()</code> function from package <a href="https://cran.r-project.org/package=nlme" class="external-link">nlme</a> <span class="citation">(Pinheiro and Bates 2000)</span> for this, because the
weighting matrix <span class="math inline">\(\boldsymbol{W}\)</span> is
non-diagonal. Instead, <span class="math inline">\(q_1\)</span> or <span class="math inline">\(q_2\)</span> are minimized using the function
<code>nlminb</code> from the standard <em>R</em> package “stats” or some
other optimizer chosen by the user.</p>
</div>
</div>
<div class="section level2">
<h2 id="the-solomon-cox-approximation-and-mql">The Solomon-Cox approximation and MQL<a class="anchor" aria-label="anchor" href="#the-solomon-cox-approximation-and-mql"></a>
</h2>
<div class="section level3">
<h3 id="the-solomon-cox-approximation">The Solomon-Cox approximation<a class="anchor" aria-label="anchor" href="#the-solomon-cox-approximation"></a>
</h3>
<p>The (first-order) Solomon approximation <span class="citation">(Solomon and Cox 1992)</span> is based on the quadratic
expansion the integrand</p>
<p><span class="math display">\[
\ell_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})\approx
\ell(\boldsymbol{y}|\boldsymbol{0};\boldsymbol{\alpha})
+
\boldsymbol{g}_0'
\boldsymbol{b}
-
\frac12
\boldsymbol{b}'
\boldsymbol{H}_0
\boldsymbol{b}
-\frac12\ln\det(\boldsymbol{\Sigma})
-\frac12\boldsymbol{b}'\boldsymbol{\Sigma}^{-1}\boldsymbol{b}
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{g}\_0=\boldsymbol{g}(\boldsymbol{0})\)</span>
is the gradient of <span class="math inline">\(\ell(\boldsymbol{y}\|\boldsymbol{b};\boldsymbol{\alpha})\)</span></p>
<p><span class="math display">\[
\boldsymbol{g}(\boldsymbol{b})=-\frac{\partial\ell(\boldsymbol{y}|\boldsymbol{b};\boldsymbol{\alpha})}{\partial\boldsymbol{b}}
\]</span></p>
<p>at <span class="math inline">\(\boldsymbol{b}=\boldsymbol{0}\)</span>, while
<span class="math inline">\(\boldsymbol{H}\_0=\boldsymbol{H}(\boldsymbol{0})\)</span>
is the negative Hessian at <span class="math inline">\(\boldsymbol{b}=\boldsymbol{0}\)</span>.</p>
<p>Like before, the integral of the exponential this quadratic expansion
(which we refer to as <span class="math inline">\(\ell_{\text{SC}}(\boldsymbol{y},\boldsymbol{b})\)</span>)
has a closed-form solution, as does its logarithm, which is:</p>
<p><span class="math display">\[
\ln\int \exp(\ell_{\text{SC}}(\boldsymbol{y},\boldsymbol{b}))
\partial\boldsymbol{b}
=
\ell(\boldsymbol{y}|\boldsymbol{0};\boldsymbol{\alpha})
-
\frac12\boldsymbol{g}_0'\left(\boldsymbol{H}_0+\boldsymbol{\Sigma}^{-1}\right)^{-1}\boldsymbol{g}_0
-
\frac12\ln\det(\boldsymbol{\Sigma})
-
\frac12\ln\det\left(\boldsymbol{H}_0+\boldsymbol{\Sigma}^{-1}\right).
\]</span></p>
</div>
<div class="section level3">
<h3 id="marginal-quasi-likelhood-mql">Marginal quasi-likelhood (MQL)<a class="anchor" aria-label="anchor" href="#marginal-quasi-likelhood-mql"></a>
</h3>
<p>The resulting estimation technique is very similar to PQL <span class="citation">(again, see Breslow and Clayton 1993 for a
discussion)</span>. The only difference is the construction of the
“working dependent” variable <span class="math inline">\(\boldsymbol{y}^*\)</span>. With PQL it is
constructed as <span class="math display">\[\boldsymbol{y}^* =
\boldsymbol{X}\boldsymbol{\alpha} + \boldsymbol{Z}\boldsymbol{b} +
\boldsymbol{W}^{-}(\boldsymbol{y}-\boldsymbol{\pi})\]</span> while the
MQL working dependent variable is just</p>
<p><span class="math display">\[
\boldsymbol{y}^* =  \boldsymbol{X}\boldsymbol{\alpha} +
\boldsymbol{W}^{-}(\boldsymbol{y}-\boldsymbol{\pi})
\]</span></p>
<p>so that the algorithm has the following steps:</p>
<ol style="list-style-type: decimal">
<li>Create some suitable starting values for <span class="math inline">\(\boldsymbol{\pi}\)</span>, <span class="math inline">\(\boldsymbol{W}\)</span>, and <span class="math inline">\(\boldsymbol{y}^*\)</span>
</li>
<li>Construct the “working dependent variable” <span class="math inline">\(\boldsymbol{y}^*\)</span>
</li>
<li>Minimize <span class="math inline">\(q_1\)</span> (quasi-ML) or
<span class="math inline">\(q_2\)</span> (quasi-REML) iteratively (inner
loop), to obtain an estimate of <span class="math inline">\(\boldsymbol{\Sigma}\)</span>
</li>
<li>Obtain <span class="math inline">\(\hat{\boldsymbol{\alpha}}\)</span> based on the
current estimate of <span class="math inline">\(\boldsymbol{\Sigma}\)</span>
</li>
<li>Compute updated <span class="math inline">\(\boldsymbol{\eta}=\boldsymbol{X}\boldsymbol{\alpha}\)</span>,
<span class="math inline">\(\boldsymbol{\pi}\)</span>, <span class="math inline">\(\boldsymbol{W}\)</span>.</li>
<li>If the change in <span class="math inline">\(\boldsymbol{\eta}\)</span> is smaller than a given
tolerance criterion stop the algorighm and declare it as converged.
Otherwise go back to step 2 with the updated values of <span class="math inline">\(\hat{\boldsymbol{\alpha}}\)</span>.</li>
</ol>
</div>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-breslow.clayton:approximate.inference.glmm" class="csl-entry">
Breslow, Norman E., and David G. Clayton. 1993. <span>“Approximate
Inference in Generalized Linear Mixed Models.”</span> <em>Journal of the
American Statistical Association</em> 88 (421): 9–25.
</div>
<div id="ref-harville:matrix.algebra" class="csl-entry">
Harville, David A. 1997. <em>Matrix Algebra from a Statistician’s
Perspective</em>. New York: Springer.
</div>
<div id="ref-nlme-book" class="csl-entry">
Pinheiro, José C., and Douglas M. Bates. 2000. <em>Mixed-Effects Models
in s and s-PLUS</em>. New York: Springer. <a href="https://doi.org/10.1007/b98882" class="external-link">https://doi.org/10.1007/b98882</a>.
</div>
<div id="ref-Solomon.Cox:1992" class="csl-entry">
Solomon, P. J., and D. R. Cox. 1992. <span>“Nonlinear Component of
Variance Models.”</span> <em>Biometrika</em> 79 (1): 1–11. <a href="https://doi.org/10.1093/biomet/79.1.1" class="external-link">https://doi.org/10.1093/biomet/79.1.1</a>.
</div>
<div id="ref-MASS" class="csl-entry">
Venables, W. N., and B. D. Ripley. 2002. <em>Modern Applied Statistics
with s</em>. Fourth. New York: Springer. <a href="https://www.stats.ox.ac.uk/pub/MASS4/" class="external-link">https://www.stats.ox.ac.uk/pub/MASS4/</a>.
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Martin Elff.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
  <p class="preferably">Using <a href="https://preferably.amirmasoudabdol.name/?source=footer" class="external-link">preferably</a> template.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
