<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Approximate Inference for Multinomial Logit Models with Random Effects • mclogit</title>
<!-- katex math --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><script src="../katex-auto.js"></script><script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Approximate Inference for Multinomial Logit Models with Random Effects">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">mclogit</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.9.17.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>The statistical models</h6></li>
    <li><a class="dropdown-item" href="../articles/conditional-logit.html">Conditional logit models</a></li>
    <li><a class="dropdown-item" href="../articles/baseline-logit.html">Baseline-category logit models</a></li>
    <li><a class="dropdown-item" href="../articles/baseline-and-conditional-logit.html">The relation between baseline logit and conditional logit models</a></li>
    <li><a class="dropdown-item" href="../articles/random-effects.html">Random effects in baseline logit models and conditional logit models</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Technical aspects of model fitting</h6></li>
    <li><a class="dropdown-item" href="../articles/fitting-mclogit.html">The IWLS algorithm used to fit conditional logit models</a></li>
    <li><a class="dropdown-item" href="../articles/approximations.html">Approximate Inference for Multinomial Logit Models with Random Effects</a></li>
    <li><a class="dropdown-item" href="../articles/Firth-bias-reduction.html">Bias reduction using Firth's penalized likelihood technique</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/melff/mclogit/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch">
<li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul>
</li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Approximate Inference for Multinomial Logit Models with Random Effects</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/melff/mclogit/blob/main/vignettes/approximations.Rmd" class="external-link"><code>vignettes/approximations.Rmd</code></a></small>
      <div class="d-none name"><code>approximations.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="the-problem">The problem<a class="anchor" aria-label="anchor" href="#the-problem"></a>
</h2>
<p>A crucial problem for inference about non-linear models with random
effects is that the likelihood function for such models involves
integrals for which no analytical solution exists.</p>
<p>For given values <span class="math inline">\boldsymbol{b}</span> of
the random effects the likelihood function of a conditional logit model
(and therefore also of a baseline-logit model) can be written in the
form</p>
<p><span class="math display">
\mathcal{L}_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})
=
\exp\left(\ell_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})\right)
=\exp
\left(
\ell(\boldsymbol{y}|\boldsymbol{b};\boldsymbol{\alpha})
-\frac12\ln\det(\boldsymbol{\Sigma})
-\frac12\boldsymbol{b}'\boldsymbol{\Sigma}^{-1}\boldsymbol{b}
\right)
</span></p>
<p>However, this “complete data” likelihood function cannot be used for
inference, because it depends on the unobserved random effects. To
arrive at a likelihood function that depends only on observed data, one
needs to used the following integrated likelihood function:</p>
<p><span class="math display">
\mathcal{L}_{\text{obs}}(\boldsymbol{y})
=
\int
\exp\left(\ell_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})\right)
\partial \boldsymbol{b}
=
\int
\exp
\left(
\ell(\boldsymbol{y}|\boldsymbol{b};\boldsymbol{\alpha})
-\frac12\ln\det(\boldsymbol{\Sigma})
-\frac12\boldsymbol{b}'\boldsymbol{\Sigma}^{-1}\boldsymbol{b}
\right)
\partial \boldsymbol{b}
</span></p>
<p>In general, this integral cannot be “solved”, i.e. eliminated from
the formula by analytic means (it is “analytically untractable”).
Instead, one will compute it either using numeric techniques (e.g. using
numerical quadrature) or approximate it using analytical techniques.
Unless there is only a single level of random effects numerical
quadrature can become computationally be demanding, that is, the
computation of the (log-)likelihood function and its derivatives can
take a lot of time even on modern, state-of-the-art computer hardware.
Yet approximations based on analytical techniques hand may lead to
biased estimates in particular in samples where the number of
observations relative to the number of random offects is small, but at
least they are much easier to compute and sometimes making inference
possible after all.</p>
<p>The package “mclogit” supports to kinds of analytical approximations,
the Laplace approximation and what one may call the Solomon-Cox
appoximation. Both approximations are based on a quadratic expansion of
the integrand so that the thus modified integral does have a closed-form
solution, i.e. is analytically tractable.</p>
</div>
<div class="section level2">
<h2 id="the-laplace-approximation-and-pql">The Laplace approximation and PQL<a class="anchor" aria-label="anchor" href="#the-laplace-approximation-and-pql"></a>
</h2>
<div class="section level3">
<h3 id="laplace-approximation">Laplace approximation<a class="anchor" aria-label="anchor" href="#laplace-approximation"></a>
</h3>
<p>The (first-order) Laplace approximation is based on the quadratic
expansion the logarithm of the integrand, the complete-data
log-likelihood</p>
<p><span class="math display">
\ell_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})\approx
\ell(\boldsymbol{y}|\tilde{\boldsymbol{b}};\boldsymbol{\alpha})
-
\frac12
(\boldsymbol{b}-\tilde{\boldsymbol{b}})'
\tilde{\boldsymbol{H}}
(\boldsymbol{b}-\tilde{\boldsymbol{b}})
-\frac12\ln\det(\boldsymbol{\Sigma})
-\frac12(\boldsymbol{b}-\tilde{\boldsymbol{b}})'\boldsymbol{\Sigma}^{-1}(\boldsymbol{b}-\tilde{\boldsymbol{b}})
</span></p>
<p>where <span class="math inline">\tilde{\boldsymbol{b}}</span> is the
solution to</p>
<p><span class="math display">
\frac{\partial\ell_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})}{\partial\boldsymbol{b}}
= 0
</span></p>
<p>and <span class="math inline">\tilde{\boldsymbol{H}}=\boldsymbol{H}(\tilde{\boldsymbol{b}})</span>
is the value of the negative Hessian with respect to <span class="math inline">\boldsymbol{b}</span></p>
<p><span class="math display">
\boldsymbol{H}(\boldsymbol{b})=-\frac{\partial^2\ell(\boldsymbol{y}|\boldsymbol{b};\boldsymbol{\alpha})}{\partial\boldsymbol{b}\partial\boldsymbol{b}'}
</span></p>
<p>for <span class="math inline">\boldsymbol{b}=\tilde{\boldsymbol{b}}</span>.</p>
<p>Since this quadratic expansion—let us call it <span class="math inline">\ell^*_{\text{Lapl}}(\boldsymbol{y},\boldsymbol{b})</span>—is
a (multivariate) quadratic function of <span class="math inline">\boldsymbol{b}</span>, the integral of its
exponential does have a closed-form solution (the relevant formula can
be found in <span class="citation">Harville (1997)</span>).</p>
<p>For purposes of estimation, the resulting approximate log-likelihood
is more useful:</p>
<p><span class="math display">
\ell^*_{\text{Lapl}}
=
\ln\int \exp(\ell_{\text{Lapl}}(\boldsymbol{y},\boldsymbol{b}))
\partial\boldsymbol{b}
=
\ell(\boldsymbol{y}|\tilde{\boldsymbol{b}};\boldsymbol{\alpha})
-
\frac12\tilde{\boldsymbol{b}}'\boldsymbol{\Sigma}^{-1}\tilde{\boldsymbol{b}}
-
\frac12\ln\det(\boldsymbol{\Sigma})
-
\frac12\ln\det\left(\tilde{\boldsymbol{H}}+\boldsymbol{\Sigma}^{-1}\right).
</span></p>
</div>
<div class="section level3">
<h3 id="penalized-quasi-likelihood-pql">Penalized quasi-likelihood (PQL)<a class="anchor" aria-label="anchor" href="#penalized-quasi-likelihood-pql"></a>
</h3>
<p>If one disregards the dependence of <span class="math inline">\tilde{\boldsymbol{H}}</span> on <span class="math inline">\boldsymbol{\alpha}</span> and <span class="math inline">\boldsymbol{b}</span>, then <span class="math inline">\tilde{\boldsymbol{b}}</span> maximizes not only
<span class="math inline">\ell_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})</span>
but also <span class="math inline">\ell^*_{\text{Lapl}}</span>. This
motivates the following IWLS/Fisher scoring equations for <span class="math inline">\hat{\boldsymbol{\alpha}}</span> and <span class="math inline">\tilde{\boldsymbol{b}}</span> (see <span class="citation">Breslow and Clayton (1993)</span> and <a href="fitting-mclogit.html">this page</a>):</p>
<p><span class="math display">
\begin{aligned}
\begin{bmatrix}
\boldsymbol{X}'\boldsymbol{W}\boldsymbol{X} &amp;
\boldsymbol{X}'\boldsymbol{W}\boldsymbol{Z} \\
\boldsymbol{Z}'\boldsymbol{W}\boldsymbol{X} &amp;
\boldsymbol{Z}'\boldsymbol{W}\boldsymbol{Z} +
\boldsymbol{\Sigma}^{-1}\\
\end{bmatrix}
\begin{bmatrix}
\hat{\boldsymbol{\alpha}}\\
\tilde{\boldsymbol{b}}\\
\end{bmatrix}
=
\begin{bmatrix}
\boldsymbol{X}'\boldsymbol{W}\boldsymbol{y}^*\\
\boldsymbol{Z}'\boldsymbol{W}\boldsymbol{y}^*
\end{bmatrix}
\end{aligned}
</span></p>
<p>where</p>
<p><span class="math display">
\boldsymbol{y}^* =  \boldsymbol{X}\boldsymbol{\alpha} +
\boldsymbol{Z}\boldsymbol{b} +
\boldsymbol{W}^{-}(\boldsymbol{y}-\boldsymbol{\pi})
</span></p>
<p>is the IWLS “working dependend variable” with <span class="math inline">\boldsymbol{\alpha}</span>, <span class="math inline">\boldsymbol{b}</span>, <span class="math inline">\boldsymbol{W}</span>, and <span class="math inline">\boldsymbol{\pi}</span> computed in an earlier
iteration.</p>
<p>Substitutions lead to the equations:</p>
<p><span class="math display">
(\boldsymbol{X}\boldsymbol{V}^-\boldsymbol{X})\hat{\boldsymbol{\alpha}}
=
\boldsymbol{X}\boldsymbol{V}^-\boldsymbol{y}^*
</span></p>
<p>and</p>
<p><span class="math display">
(\boldsymbol{Z}'\boldsymbol{W}\boldsymbol{Z} +
\boldsymbol{\Sigma}^{-1})\boldsymbol{b} =
\boldsymbol{Z}'\boldsymbol{W}(\boldsymbol{y}^*-\boldsymbol{X}\boldsymbol{\alpha})
</span></p>
<p>which can be solved to compute <span class="math inline">\hat{\boldsymbol{\alpha}}</span> and <span class="math inline">\tilde{\boldsymbol{b}}</span> (for given <span class="math inline">\boldsymbol{\Sigma}</span>)</p>
<p>Here</p>
<p><span class="math display">
\boldsymbol{V} =
\boldsymbol{W}^-+\boldsymbol{Z}\boldsymbol{\Sigma}\boldsymbol{Z}'
</span></p>
<p>and</p>
<p><span class="math display">
\boldsymbol{V}^- = \boldsymbol{W}-
\boldsymbol{W}\boldsymbol{Z}'\left(\boldsymbol{Z}'\boldsymbol{W}\boldsymbol{Z}+\boldsymbol{\Sigma}^{-1}\right)^{-1}\boldsymbol{Z}\boldsymbol{W}
</span></p>
<p>Following <span class="citation">Breslow and Clayton (1993)</span>
the variance parameters in <span class="math inline">\boldsymbol{\Sigma}</span> are estimated by
minimizing</p>
<p><span class="math display">
q_1 =
\det(\boldsymbol{V})+(\boldsymbol{y}^*-\boldsymbol{X}\boldsymbol{\alpha})\boldsymbol{V}^-(\boldsymbol{y}^*-\boldsymbol{X}\boldsymbol{\alpha})
</span></p>
<p>or the “REML” variant:</p>
<p><span class="math display">
q_2 =
\det(\boldsymbol{V})+(\boldsymbol{y}^*-\boldsymbol{X}\boldsymbol{\alpha})\boldsymbol{V}^-(\boldsymbol{y}^*-\boldsymbol{X}\boldsymbol{\alpha})+\det(\boldsymbol{X}'\boldsymbol{V}^{-}\boldsymbol{X})
</span></p>
<p>This motivates the following algorithm, which is strongly inspired by
the <code><a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html" class="external-link">glmmPQL()</a></code> function in Brian Ripley’s <em>R</em> package
<a href="https://cran.r-project.org/package=MASS" class="external-link">MASS</a> <span class="citation">(Venables and Ripley 2002)</span>:</p>
<ol style="list-style-type: decimal">
<li>Create some suitable starting values for <span class="math inline">\boldsymbol{\pi}</span>, <span class="math inline">\boldsymbol{W}</span>, and <span class="math inline">\boldsymbol{y}^*</span>
</li>
<li>Construct the “working dependent variable” <span class="math inline">\boldsymbol{y}^*</span>
</li>
<li>Minimize <span class="math inline">q_1</span> (quasi-ML) or <span class="math inline">q_2</span> (quasi-REML) iteratively (inner loop), to
obtain an estimate of <span class="math inline">\boldsymbol{\Sigma}</span>
</li>
<li>Obtain <span class="math inline">hat{\boldsymbol{\alpha}}</span> and
<span class="math inline">\tilde{\boldsymbol{b}}</span> based on the
current estimate of <span class="math inline">\boldsymbol{\Sigma}</span>
</li>
<li>Compute updated <span class="math inline">\boldsymbol{\eta}=\boldsymbol{X}\boldsymbol{\alpha}
+
\boldsymbol{Z}\boldsymbol{b}</span>, <span class="math inline">\boldsymbol{\pi}</span>, <span class="math inline">\boldsymbol{W}</span>.</li>
<li>If the change in <span class="math inline">\boldsymbol{\eta}</span>
is smaller than a given tolerance criterion stop the algorighm and
declare it as converged. Otherwise go back to step 2 with the updated
values of <span class="math inline">\hat{\boldsymbol{\alpha}}</span> and
<span class="math inline">\tilde{\boldsymbol{b}}</span>.</li>
</ol>
<p>This algorithm is a modification of the <a href="fitting-mclogit.html">IWLS</a> algorithm used to fit conditional
logit models without random effects. Instead of just solving a linear
requatoin in step 3, it estimates a weighted linear mixed-effects model.
In contrast to <code><a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html" class="external-link">glmmPQL()</a></code> it does not use the
<code>lme()</code> function from package <a href="https://cran.r-project.org/package=nlme" class="external-link">nlme</a> <span class="citation">(Pinheiro and Bates 2000)</span> for this, because the
weighting matrix <span class="math inline">\boldsymbol{W}</span> is
non-diagonal. Instead, <span class="math inline">q_1</span> or <span class="math inline">q_2</span> are minimized using the function
<code>nlminb</code> from the standard <em>R</em> package “stats” or some
other optimizer chosen by the user.</p>
</div>
</div>
<div class="section level2">
<h2 id="the-solomon-cox-approximation-and-mql">The Solomon-Cox approximation and MQL<a class="anchor" aria-label="anchor" href="#the-solomon-cox-approximation-and-mql"></a>
</h2>
<div class="section level3">
<h3 id="the-solomon-cox-approximation">The Solomon-Cox approximation<a class="anchor" aria-label="anchor" href="#the-solomon-cox-approximation"></a>
</h3>
<p>The (first-order) Solomon approximation <span class="citation">(Solomon and Cox 1992)</span> is based on the quadratic
expansion the integrand</p>
<p><span class="math display">
\ell_{\text{cpl}}(\boldsymbol{y},\boldsymbol{b})\approx
\ell(\boldsymbol{y}|\boldsymbol{0};\boldsymbol{\alpha})
+
\boldsymbol{g}_0'
\boldsymbol{b}
-
\frac12
\boldsymbol{b}'
\boldsymbol{H}_0
\boldsymbol{b}
-\frac12\ln\det(\boldsymbol{\Sigma})
-\frac12\boldsymbol{b}'\boldsymbol{\Sigma}^{-1}\boldsymbol{b}
</span></p>
<p>where <span class="math inline">\boldsymbol{g}\_0=\boldsymbol{g}(\boldsymbol{0})</span>
is the gradient of <span class="math inline">\ell(\boldsymbol{y}\|\boldsymbol{b};\boldsymbol{\alpha})</span></p>
<p><span class="math display">
\boldsymbol{g}(\boldsymbol{b})=-\frac{\partial\ell(\boldsymbol{y}|\boldsymbol{b};\boldsymbol{\alpha})}{\partial\boldsymbol{b}}
</span></p>
<p>at <span class="math inline">\boldsymbol{b}=\boldsymbol{0}</span>,
while <span class="math inline">\boldsymbol{H}\_0=\boldsymbol{H}(\boldsymbol{0})</span>
is the negative Hessian at <span class="math inline">\boldsymbol{b}=\boldsymbol{0}</span>.</p>
<p>Like before, the integral of the exponential this quadratic expansion
(which we refer to as <span class="math inline">\ell_{\text{SC}}(\boldsymbol{y},\boldsymbol{b})</span>)
has a closed-form solution, as does its logarithm, which is:</p>
<p><span class="math display">
\ln\int \exp(\ell_{\text{SC}}(\boldsymbol{y},\boldsymbol{b}))
\partial\boldsymbol{b}
=
\ell(\boldsymbol{y}|\boldsymbol{0};\boldsymbol{\alpha})
-
\frac12\boldsymbol{g}_0'\left(\boldsymbol{H}_0+\boldsymbol{\Sigma}^{-1}\right)^{-1}\boldsymbol{g}_0
-
\frac12\ln\det(\boldsymbol{\Sigma})
-
\frac12\ln\det\left(\boldsymbol{H}_0+\boldsymbol{\Sigma}^{-1}\right).
</span></p>
</div>
<div class="section level3">
<h3 id="marginal-quasi-likelhood-mql">Marginal quasi-likelhood (MQL)<a class="anchor" aria-label="anchor" href="#marginal-quasi-likelhood-mql"></a>
</h3>
<p>The resulting estimation technique is very similar to PQL <span class="citation">(again, see Breslow and Clayton 1993 for a
discussion)</span>. The only difference is the construction of the
“working dependent” variable <span class="math inline">\boldsymbol{y}^*</span>. With PQL it is constructed
as <span class="math display">\boldsymbol{y}^* =
\boldsymbol{X}\boldsymbol{\alpha} + \boldsymbol{Z}\boldsymbol{b} +
\boldsymbol{W}^{-}(\boldsymbol{y}-\boldsymbol{\pi})</span> while the MQL
working dependent variable is just</p>
<p><span class="math display">
\boldsymbol{y}^* =  \boldsymbol{X}\boldsymbol{\alpha} +
\boldsymbol{W}^{-}(\boldsymbol{y}-\boldsymbol{\pi})
</span></p>
<p>so that the algorithm has the following steps:</p>
<ol style="list-style-type: decimal">
<li>Create some suitable starting values for <span class="math inline">\boldsymbol{\pi}</span>, <span class="math inline">\boldsymbol{W}</span>, and <span class="math inline">\boldsymbol{y}^*</span>
</li>
<li>Construct the “working dependent variable” <span class="math inline">\boldsymbol{y}^*</span>
</li>
<li>Minimize <span class="math inline">q_1</span> (quasi-ML) or <span class="math inline">q_2</span> (quasi-REML) iteratively (inner loop), to
obtain an estimate of <span class="math inline">\boldsymbol{\Sigma}</span>
</li>
<li>Obtain <span class="math inline">\hat{\boldsymbol{\alpha}}</span>
based on the current estimate of <span class="math inline">\boldsymbol{\Sigma}</span>
</li>
<li>Compute updated <span class="math inline">\boldsymbol{\eta}=\boldsymbol{X}\boldsymbol{\alpha}</span>,
<span class="math inline">\boldsymbol{\pi}</span>, <span class="math inline">\boldsymbol{W}</span>.</li>
<li>If the change in <span class="math inline">\boldsymbol{\eta}</span>
is smaller than a given tolerance criterion stop the algorighm and
declare it as converged. Otherwise go back to step 2 with the updated
values of <span class="math inline">\hat{\boldsymbol{\alpha}}</span>.</li>
</ol>
</div>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-breslow.clayton:approximate.inference.glmm" class="csl-entry">
Breslow, Norman E., and David G. Clayton. 1993. <span>“Approximate
Inference in Generalized Linear Mixed Models.”</span> <em>Journal of the
American Statistical Association</em> 88 (421): 9–25.
</div>
<div id="ref-harville:matrix.algebra" class="csl-entry">
Harville, David A. 1997. <em>Matrix Algebra from a Statistician’s
Perspective</em>. New York: Springer.
</div>
<div id="ref-nlme-book" class="csl-entry">
Pinheiro, José C., and Douglas M. Bates. 2000. <em>Mixed-Effects Models
in s and s-PLUS</em>. New York: Springer. <a href="https://doi.org/10.1007/b98882" class="external-link">https://doi.org/10.1007/b98882</a>.
</div>
<div id="ref-Solomon.Cox:1992" class="csl-entry">
Solomon, P. J., and D. R. Cox. 1992. <span>“Nonlinear Component of
Variance Models.”</span> <em>Biometrika</em> 79 (1): 1–11. <a href="https://doi.org/10.1093/biomet/79.1.1" class="external-link">https://doi.org/10.1093/biomet/79.1.1</a>.
</div>
<div id="ref-MASS" class="csl-entry">
Venables, W. N., and B. D. Ripley. 2002. <em>Modern Applied Statistics
with s</em>. Fourth. New York: Springer. <a href="https://www.stats.ox.ac.uk/pub/MASS4/" class="external-link">https://www.stats.ox.ac.uk/pub/MASS4/</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Martin Elff.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
