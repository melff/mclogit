[{"path":"https://melff.github.io/mclogit/articles/approximations.html","id":"the-problem","dir":"Articles","previous_headings":"","what":"The problem","title":"Approximate Inference for Multinomial Logit Models with Random Effects","text":"crucial problem inference non-linear models random effects likelihood function models involves integrals analytical solution exists. given values 𝐛\\boldsymbol{b} random effects likelihood function conditional logit model (therefore also baseline-logit model) can written form ℒcpl(𝐲,𝐛)=exp(ℓcpl(𝐲,𝐛))=exp(ℓ(𝐲|𝐛;𝛂)−12lndet(𝚺)−12𝐛′𝚺−1𝐛) \\mathcal{L}_{\\text{cpl}}(\\boldsymbol{y},\\boldsymbol{b}) = \\exp\\left(\\ell_{\\text{cpl}}(\\boldsymbol{y},\\boldsymbol{b})\\right) =\\exp \\left( \\ell(\\boldsymbol{y}|\\boldsymbol{b};\\boldsymbol{\\alpha}) -\\frac12\\ln\\det(\\boldsymbol{\\Sigma}) -\\frac12\\boldsymbol{b}'\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{b} \\right) However, “complete data” likelihood function used inference, depends unobserved random effects. arrive likelihood function depends observed data, one needs used following integrated likelihood function: ℒobs(𝐲)=∫exp(ℓcpl(𝐲,𝐛))∂𝐛=∫exp(ℓ(𝐲|𝐛;𝛂)−12lndet(𝚺)−12𝐛′𝚺−1𝐛)∂𝐛 \\mathcal{L}_{\\text{obs}}(\\boldsymbol{y}) = \\int \\exp\\left(\\ell_{\\text{cpl}}(\\boldsymbol{y},\\boldsymbol{b})\\right) \\partial \\boldsymbol{b} = \\int \\exp \\left( \\ell(\\boldsymbol{y}|\\boldsymbol{b};\\boldsymbol{\\alpha}) -\\frac12\\ln\\det(\\boldsymbol{\\Sigma}) -\\frac12\\boldsymbol{b}'\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{b} \\right) \\partial \\boldsymbol{b} general, integral “solved”, .e. eliminated formula analytic means (“analytically untractable”). Instead, one compute either using numeric techniques (e.g. using numerical quadrature) approximate using analytical techniques. Unless single level random effects numerical quadrature can become computationally demanding, , computation (log-)likelihood function derivatives can take lot time even modern, state---art computer hardware. Yet approximations based analytical techniques hand may lead biased estimates particular samples number observations relative number random offects small, least much easier compute sometimes making inference possible . package “mclogit” supports kinds analytical approximations, Laplace approximation one may call Solomon-Cox appoximation. approximations based quadratic expansion integrand thus modified integral closed-form solution, .e. analytically tractable.","code":""},{"path":[]},{"path":"https://melff.github.io/mclogit/articles/approximations.html","id":"laplace-approximation","dir":"Articles","previous_headings":"The Laplace approximation and PQL","what":"Laplace approximation","title":"Approximate Inference for Multinomial Logit Models with Random Effects","text":"(first-order) Laplace approximation based quadratic expansion logarithm integrand, complete-data log-likelihood ℓcpl(𝐲,𝐛)≈ℓ(𝐲|𝐛̃;𝛂)−12(𝐛−𝐛̃)′𝐇̃(𝐛−𝐛̃)−12lndet(𝚺)−12(𝐛−𝐛̃)′𝚺−1(𝐛−𝐛̃) \\ell_{\\text{cpl}}(\\boldsymbol{y},\\boldsymbol{b})\\approx \\ell(\\boldsymbol{y}|\\tilde{\\boldsymbol{b}};\\boldsymbol{\\alpha}) - \\frac12 (\\boldsymbol{b}-\\tilde{\\boldsymbol{b}})' \\tilde{\\boldsymbol{H}} (\\boldsymbol{b}-\\tilde{\\boldsymbol{b}}) -\\frac12\\ln\\det(\\boldsymbol{\\Sigma}) -\\frac12(\\boldsymbol{b}-\\tilde{\\boldsymbol{b}})'\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{b}-\\tilde{\\boldsymbol{b}}) 𝐛̃\\tilde{\\boldsymbol{b}} solution ∂ℓcpl(𝐲,𝐛)∂𝐛=0 \\frac{\\partial\\ell_{\\text{cpl}}(\\boldsymbol{y},\\boldsymbol{b})}{\\partial\\boldsymbol{b}} = 0 𝐇̃=𝐇(𝐛̃)\\tilde{\\boldsymbol{H}}=\\boldsymbol{H}(\\tilde{\\boldsymbol{b}}) value negative Hessian respect 𝐛\\boldsymbol{b} 𝐇(𝐛)=−∂2ℓ(𝐲|𝐛;𝛂)∂𝐛∂𝐛′ \\boldsymbol{H}(\\boldsymbol{b})=-\\frac{\\partial^2\\ell(\\boldsymbol{y}|\\boldsymbol{b};\\boldsymbol{\\alpha})}{\\partial\\boldsymbol{b}\\partial\\boldsymbol{b}'} 𝐛=𝐛̃\\boldsymbol{b}=\\tilde{\\boldsymbol{b}}. Since quadratic expansion—let us call ℓLapl*(𝐲,𝐛)\\ell^*_{\\text{Lapl}}(\\boldsymbol{y},\\boldsymbol{b})—(multivariate) quadratic function 𝐛\\boldsymbol{b}, integral exponential closed-form solution (relevant formula can found Harville (1997)). purposes estimation, resulting approximate log-likelihood useful: ℓLapl*=ln∫exp(ℓLapl(𝐲,𝐛))∂𝐛=ℓ(𝐲|𝐛̃;𝛂)−12𝐛̃′𝚺−1𝐛̃−12lndet(𝚺)−12lndet(𝐇̃+𝚺−1). \\ell^*_{\\text{Lapl}} = \\ln\\int \\exp(\\ell_{\\text{Lapl}}(\\boldsymbol{y},\\boldsymbol{b})) \\partial\\boldsymbol{b} = \\ell(\\boldsymbol{y}|\\tilde{\\boldsymbol{b}};\\boldsymbol{\\alpha}) - \\frac12\\tilde{\\boldsymbol{b}}'\\boldsymbol{\\Sigma}^{-1}\\tilde{\\boldsymbol{b}} - \\frac12\\ln\\det(\\boldsymbol{\\Sigma}) - \\frac12\\ln\\det\\left(\\tilde{\\boldsymbol{H}}+\\boldsymbol{\\Sigma}^{-1}\\right).","code":""},{"path":"https://melff.github.io/mclogit/articles/approximations.html","id":"penalized-quasi-likelihood-pql","dir":"Articles","previous_headings":"The Laplace approximation and PQL","what":"Penalized quasi-likelihood (PQL)","title":"Approximate Inference for Multinomial Logit Models with Random Effects","text":"one disregards dependence 𝐇̃\\tilde{\\boldsymbol{H}} 𝛂\\boldsymbol{\\alpha} 𝐛\\boldsymbol{b}, 𝐛̃\\tilde{\\boldsymbol{b}} maximizes ℓcpl(𝐲,𝐛)\\ell_{\\text{cpl}}(\\boldsymbol{y},\\boldsymbol{b}) also ℓLapl*\\ell^*_{\\text{Lapl}}. motivates following IWLS/Fisher scoring equations 𝛂̂\\hat{\\boldsymbol{\\alpha}} 𝐛̃\\tilde{\\boldsymbol{b}} (see Breslow Clayton (1993) page): [𝐗′𝐖𝐗𝐗′𝐖𝐙𝐙′𝐖𝐗𝐙′𝐖𝐙+𝚺−1][𝛂̂𝐛̃]=[𝐗′𝐖𝐲*𝐙′𝐖𝐲*] \\begin{aligned} \\begin{bmatrix} \\boldsymbol{X}'\\boldsymbol{W}\\boldsymbol{X} & \\boldsymbol{X}'\\boldsymbol{W}\\boldsymbol{Z} \\\\ \\boldsymbol{Z}'\\boldsymbol{W}\\boldsymbol{X} & \\boldsymbol{Z}'\\boldsymbol{W}\\boldsymbol{Z} + \\boldsymbol{\\Sigma}^{-1}\\\\ \\end{bmatrix} \\begin{bmatrix}  \\hat{\\boldsymbol{\\alpha}}\\\\  \\tilde{\\boldsymbol{b}}\\\\ \\end{bmatrix}  = \\begin{bmatrix} \\boldsymbol{X}'\\boldsymbol{W}\\boldsymbol{y}^*\\\\ \\boldsymbol{Z}'\\boldsymbol{W}\\boldsymbol{y}^* \\end{bmatrix} \\end{aligned} 𝐲*=𝐗𝛂+𝐙𝐛+𝐖−(𝐲−𝛑) \\boldsymbol{y}^* =  \\boldsymbol{X}\\boldsymbol{\\alpha} + \\boldsymbol{Z}\\boldsymbol{b} + \\boldsymbol{W}^{-}(\\boldsymbol{y}-\\boldsymbol{\\pi}) IWLS “working dependend variable” 𝛂\\boldsymbol{\\alpha}, 𝐛\\boldsymbol{b}, 𝐖\\boldsymbol{W}, 𝛑\\boldsymbol{\\pi} computed earlier iteration. Substitutions lead equations: (𝐗𝐕−𝐗)𝛂̂=𝐗𝐕−𝐲* (\\boldsymbol{X}\\boldsymbol{V}^-\\boldsymbol{X})\\hat{\\boldsymbol{\\alpha}} = \\boldsymbol{X}\\boldsymbol{V}^-\\boldsymbol{y}^* (𝐙′𝐖𝐙+𝚺−1)𝐛=𝐙′𝐖(𝐲*−𝐗𝛂) (\\boldsymbol{Z}'\\boldsymbol{W}\\boldsymbol{Z} + \\boldsymbol{\\Sigma}^{-1})\\boldsymbol{b} = \\boldsymbol{Z}'\\boldsymbol{W}(\\boldsymbol{y}^*-\\boldsymbol{X}\\boldsymbol{\\alpha}) can solved compute 𝛂̂\\hat{\\boldsymbol{\\alpha}} 𝐛̃\\tilde{\\boldsymbol{b}} (given 𝚺\\boldsymbol{\\Sigma}) 𝐕=𝐖−+𝐙𝚺𝐙′ \\boldsymbol{V} = \\boldsymbol{W}^-+\\boldsymbol{Z}\\boldsymbol{\\Sigma}\\boldsymbol{Z}' 𝐕−=𝐖−𝐖𝐙′(𝐙′𝐖𝐙+𝚺−1)−1𝐙𝐖 \\boldsymbol{V}^- = \\boldsymbol{W}- \\boldsymbol{W}\\boldsymbol{Z}'\\left(\\boldsymbol{Z}'\\boldsymbol{W}\\boldsymbol{Z}+\\boldsymbol{\\Sigma}^{-1}\\right)^{-1}\\boldsymbol{Z}\\boldsymbol{W} Following Breslow Clayton (1993) variance parameters 𝚺\\boldsymbol{\\Sigma} estimated minimizing q1=det(𝐕)+(𝐲*−𝐗𝛂)𝐕−(𝐲*−𝐗𝛂) q_1 = \\det(\\boldsymbol{V})+(\\boldsymbol{y}^*-\\boldsymbol{X}\\boldsymbol{\\alpha})\\boldsymbol{V}^-(\\boldsymbol{y}^*-\\boldsymbol{X}\\boldsymbol{\\alpha}) “REML” variant: q2=det(𝐕)+(𝐲*−𝐗𝛂)𝐕−(𝐲*−𝐗𝛂)+det(𝐗′𝐕−𝐗) q_2 = \\det(\\boldsymbol{V})+(\\boldsymbol{y}^*-\\boldsymbol{X}\\boldsymbol{\\alpha})\\boldsymbol{V}^-(\\boldsymbol{y}^*-\\boldsymbol{X}\\boldsymbol{\\alpha})+\\det(\\boldsymbol{X}'\\boldsymbol{V}^{-}\\boldsymbol{X}) motivates following algorithm, strongly inspired glmmPQL() function Brian Ripley’s R package MASS (Venables Ripley 2002): Create suitable starting values 𝛑\\boldsymbol{\\pi}, 𝐖\\boldsymbol{W}, 𝐲*\\boldsymbol{y}^* Construct “working dependent variable” 𝐲*\\boldsymbol{y}^* Minimize q1q_1 (quasi-ML) q2q_2 (quasi-REML) iteratively (inner loop), obtain estimate 𝚺\\boldsymbol{\\Sigma} Obtain hat𝛂hat{\\boldsymbol{\\alpha}} 𝐛̃\\tilde{\\boldsymbol{b}} based current estimate 𝚺\\boldsymbol{\\Sigma} Compute updated 𝛈=𝐗𝛂+𝐙𝐛\\boldsymbol{\\eta}=\\boldsymbol{X}\\boldsymbol{\\alpha} + \\boldsymbol{Z}\\boldsymbol{b}, 𝛑\\boldsymbol{\\pi}, 𝐖\\boldsymbol{W}. change 𝛈\\boldsymbol{\\eta} smaller given tolerance criterion stop algorighm declare converged. Otherwise go back step 2 updated values 𝛂̂\\hat{\\boldsymbol{\\alpha}} 𝐛̃\\tilde{\\boldsymbol{b}}. algorithm modification IWLS algorithm used fit conditional logit models without random effects. Instead just solving linear requatoin step 3, estimates weighted linear mixed-effects model. contrast glmmPQL() use lme() function package nlme (Pinheiro Bates 2000) , weighting matrix 𝐖\\boldsymbol{W} non-diagonal. Instead, q1q_1 q2q_2 minimized using function nlminb standard R package “stats” optimizer chosen user.","code":""},{"path":[]},{"path":"https://melff.github.io/mclogit/articles/approximations.html","id":"the-solomon-cox-approximation","dir":"Articles","previous_headings":"The Solomon-Cox approximation and MQL","what":"The Solomon-Cox approximation","title":"Approximate Inference for Multinomial Logit Models with Random Effects","text":"(first-order) Solomon approximation (Solomon Cox 1992) based quadratic expansion integrand ℓcpl(𝐲,𝐛)≈ℓ(𝐲|𝟎;𝛂)+𝐠0′𝐛−12𝐛′𝐇0𝐛−12lndet(𝚺)−12𝐛′𝚺−1𝐛 \\ell_{\\text{cpl}}(\\boldsymbol{y},\\boldsymbol{b})\\approx \\ell(\\boldsymbol{y}|\\boldsymbol{0};\\boldsymbol{\\alpha}) + \\boldsymbol{g}_0' \\boldsymbol{b} - \\frac12 \\boldsymbol{b}' \\boldsymbol{H}_0 \\boldsymbol{b} -\\frac12\\ln\\det(\\boldsymbol{\\Sigma}) -\\frac12\\boldsymbol{b}'\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{b} 𝐠_0=𝐠(𝟎)\\boldsymbol{g}\\_0=\\boldsymbol{g}(\\boldsymbol{0}) gradient ℓ(𝐲∥𝐛;𝛂)\\ell(\\boldsymbol{y}\\|\\boldsymbol{b};\\boldsymbol{\\alpha}) 𝐠(𝐛)=−∂ℓ(𝐲|𝐛;𝛂)∂𝐛 \\boldsymbol{g}(\\boldsymbol{b})=-\\frac{\\partial\\ell(\\boldsymbol{y}|\\boldsymbol{b};\\boldsymbol{\\alpha})}{\\partial\\boldsymbol{b}} 𝐛=𝟎\\boldsymbol{b}=\\boldsymbol{0}, 𝐇_0=𝐇(𝟎)\\boldsymbol{H}\\_0=\\boldsymbol{H}(\\boldsymbol{0}) negative Hessian 𝐛=𝟎\\boldsymbol{b}=\\boldsymbol{0}. Like , integral exponential quadratic expansion (refer ℓSC(𝐲,𝐛)\\ell_{\\text{SC}}(\\boldsymbol{y},\\boldsymbol{b})) closed-form solution, logarithm, : ln∫exp(ℓSC(𝐲,𝐛))∂𝐛=ℓ(𝐲|𝟎;𝛂)−12𝐠0′(𝐇0+𝚺−1)−1𝐠0−12lndet(𝚺)−12lndet(𝐇0+𝚺−1). \\ln\\int \\exp(\\ell_{\\text{SC}}(\\boldsymbol{y},\\boldsymbol{b})) \\partial\\boldsymbol{b} = \\ell(\\boldsymbol{y}|\\boldsymbol{0};\\boldsymbol{\\alpha}) - \\frac12\\boldsymbol{g}_0'\\left(\\boldsymbol{H}_0+\\boldsymbol{\\Sigma}^{-1}\\right)^{-1}\\boldsymbol{g}_0 - \\frac12\\ln\\det(\\boldsymbol{\\Sigma}) - \\frac12\\ln\\det\\left(\\boldsymbol{H}_0+\\boldsymbol{\\Sigma}^{-1}\\right).","code":""},{"path":"https://melff.github.io/mclogit/articles/approximations.html","id":"marginal-quasi-likelhood-mql","dir":"Articles","previous_headings":"The Solomon-Cox approximation and MQL","what":"Marginal quasi-likelhood (MQL)","title":"Approximate Inference for Multinomial Logit Models with Random Effects","text":"resulting estimation technique similar PQL (, see Breslow Clayton 1993 discussion). difference construction “working dependent” variable 𝐲*\\boldsymbol{y}^*. PQL constructed 𝐲*=𝐗𝛂+𝐙𝐛+𝐖−(𝐲−𝛑)\\boldsymbol{y}^* = \\boldsymbol{X}\\boldsymbol{\\alpha} + \\boldsymbol{Z}\\boldsymbol{b} + \\boldsymbol{W}^{-}(\\boldsymbol{y}-\\boldsymbol{\\pi}) MQL working dependent variable just 𝐲*=𝐗𝛂+𝐖−(𝐲−𝛑) \\boldsymbol{y}^* =  \\boldsymbol{X}\\boldsymbol{\\alpha} + \\boldsymbol{W}^{-}(\\boldsymbol{y}-\\boldsymbol{\\pi}) algorithm following steps: Create suitable starting values 𝛑\\boldsymbol{\\pi}, 𝐖\\boldsymbol{W}, 𝐲*\\boldsymbol{y}^* Construct “working dependent variable” 𝐲*\\boldsymbol{y}^* Minimize q1q_1 (quasi-ML) q2q_2 (quasi-REML) iteratively (inner loop), obtain estimate 𝚺\\boldsymbol{\\Sigma} Obtain 𝛂̂\\hat{\\boldsymbol{\\alpha}} based current estimate 𝚺\\boldsymbol{\\Sigma} Compute updated 𝛈=𝐗𝛂\\boldsymbol{\\eta}=\\boldsymbol{X}\\boldsymbol{\\alpha}, 𝛑\\boldsymbol{\\pi}, 𝐖\\boldsymbol{W}. change 𝛈\\boldsymbol{\\eta} smaller given tolerance criterion stop algorighm declare converged. Otherwise go back step 2 updated values 𝛂̂\\hat{\\boldsymbol{\\alpha}}.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://melff.github.io/mclogit/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Martin Elff. Author, maintainer.","code":""},{"path":"https://melff.github.io/mclogit/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Elff M (2025). mclogit: Multinomial Logit Models Polychotogomous Responses Discrete Choices. R package version 0.9.14, http://melff.github.io/mclogit/.","code":"@Manual{,   title = {mclogit: Multinomial Logit Models for Polychotogomous Responses and Discrete Choices},   author = {Martin Elff},   year = {2025},   note = {R package version 0.9.14},   url = {http://melff.github.io/mclogit/}, }"},{"path":"https://melff.github.io/mclogit/index.html","id":"mclogit-multinomial-logit-models-with-or-without-random-effects-or-overdispersion","dir":"","previous_headings":"","what":"Multinomial Logit Models for Polychotogomous Responses and Discrete Choices","title":"Multinomial Logit Models for Polychotogomous Responses and Discrete Choices","text":"packages provides estimators multinomial logit models conditional logit baseline logit variants, without random effects, without overdispersion. Random effects models estimated using PQL technique (based Laplace approximation) MQL technique (based Solomon-Cox approximation). Estimates treated caution group sizes small.","code":""},{"path":"https://melff.github.io/mclogit/reference/Transport.html","id":null,"dir":"Reference","previous_headings":"","what":"Choice of Means of Transport — Transport","title":"Choice of Means of Transport — Transport","text":"artificial data set choice means transport based cost walking distance.","code":""},{"path":"https://melff.github.io/mclogit/reference/Transport.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Choice of Means of Transport — Transport","text":"","code":"data(Transport)"},{"path":"https://melff.github.io/mclogit/reference/Transport.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Choice of Means of Transport — Transport","text":"data frame containing following variables: transport means transportation can chosen. suburb identifying number suburb distance walking distance bus train station cost cost means transportation working size working population suburb prop.true true choice probabilities resp choice frequencies means transportation","code":""},{"path":"https://melff.github.io/mclogit/reference/dispersion.html","id":null,"dir":"Reference","previous_headings":"","what":"Overdispersion in Multinomial Logit Models — dispersion","title":"Overdispersion in Multinomial Logit Models — dispersion","text":"function dispersion() extracts dispersion parameter   multinomial logit model computes dispersion parameter   estimate based given method. dispersion parameter can   attached model using update(). can also given   argument summary().","code":""},{"path":"https://melff.github.io/mclogit/reference/dispersion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Overdispersion in Multinomial Logit Models — dispersion","text":"","code":"dispersion(object, method, ...) # S3 method for class 'mclogit' dispersion(object, method=NULL, ...)"},{"path":"https://melff.github.io/mclogit/reference/dispersion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Overdispersion in Multinomial Logit Models — dispersion","text":"object object inherits class \"mclogit\".     passed dispersion(),     result call mclogit()     mblogit(), without random effects. method character string, either \"Afroz\",     \"Fletcher\", \"Pearson\", \"Deviance\",     specifies estimator dispersion;     NULL, case default estimator, \"Afroz\"     used. estimators discussed Afroz et al. (2019). ... arguments, ignored passed methods.","code":""},{"path":"https://melff.github.io/mclogit/reference/dispersion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Overdispersion in Multinomial Logit Models — dispersion","text":"Afroz, Farzana, Matt Parry, David Fletcher. (2020).   \"Estimating Overdispersion Sparse Multinomial Data.\"   Biometrics 76(3): 834-842. doi:10.1111/biom.13194 .","code":""},{"path":"https://melff.github.io/mclogit/reference/dispersion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Overdispersion in Multinomial Logit Models — dispersion","text":"","code":"library(MASS) # For 'housing' data  # Note that with a factor response and frequency weighted data, # Overdispersion will be overestimated: house.mblogit <- mblogit(Sat ~ Infl + Type + Cont,                           weights = Freq,                          data = housing) #>  #> Iteration 1 - deviance = 3493.764 - criterion = 0.9614469 #> Iteration 2 - deviance = 3470.111 - criterion = 0.00681597 #> Iteration 3 - deviance = 3470.084 - criterion = 7.82437e-06 #> Iteration 4 - deviance = 3470.084 - criterion = 7.469596e-11 #> converged dispersion(house.mblogit, method = \"Afroz\") #> [1] 20.45129 dispersion(house.mblogit, method = \"Deviance\") #> [1] 26.69295  # In order to be able to estimate overdispersion accurately, # data like the above (which usually comes from applying # 'as.data.frame' to a contingency table) the model has to be # fitted with the optional argument 'aggregate=TRUE' or  # by requesting the dispersion in advance. house.mblogit.agg <- mblogit(Sat ~ Infl + Type + Cont,                               weights = Freq,                              data = housing,                               aggregate = TRUE) #>  #> Iteration 1 - deviance = 38.84842 - criterion = 0.992521 #> Iteration 2 - deviance = 38.66222 - criterion = 0.004803721 #> Iteration 3 - deviance = 38.6622 - criterion = 3.782555e-07 #> Iteration 4 - deviance = 38.6622 - criterion = 3.666163e-15 #> converged # Now the estimated dispersion parameter is no longer larger than 20, # but just bit over 1.0. dispersion(house.mblogit.agg, method = \"Afroz\") #> [1] 1.121765 dispersion(house.mblogit.agg, method = \"Deviance\") #> [1] 1.137124  # It is possible to obtain the dispersion after estimating the coefficients: phi.Afroz <- dispersion(house.mblogit.agg, method = \"Afroz\") summary(house.mblogit.agg, dispersion = phi.Afroz) #>  #> Call: #> mblogit(formula = Sat ~ Infl + Type + Cont, data = housing, weights = Freq,  #>     aggregate = TRUE) #>  #> Equation for Medium vs Low: #>               Estimate Std. Error t value Pr(>|t|)    #> (Intercept)    -0.4192     0.1729  -2.424  0.02081 *  #> InflMedium      0.4464     0.1416   3.153  0.00336 ** #> InflHigh        0.6649     0.1863   3.568  0.00109 ** #> TypeApartment  -0.4357     0.1725  -2.525  0.01639 *  #> TypeAtrium      0.1314     0.2231   0.589  0.55987    #> TypeTerrace    -0.6666     0.2063  -3.232  0.00273 ** #> ContHigh        0.3609     0.1324   2.726  0.01007 *  #>  #> Equation for High vs Low: #>               Estimate Std. Error t value Pr(>|t|)     #> (Intercept)    -0.1387     0.1592  -0.871 0.389681     #> InflMedium      0.7349     0.1369   5.366 5.74e-06 *** #> InflHigh        1.6126     0.1671   9.649 2.89e-11 *** #> TypeApartment  -0.7356     0.1553  -4.738 3.75e-05 *** #> TypeAtrium     -0.4080     0.2115  -1.929 0.062112 .   #> TypeTerrace    -1.4123     0.2001  -7.056 3.79e-08 *** #> ContHigh        0.4818     0.1241   3.881 0.000454 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Dispersion:  1.121765  on  34  degrees of freedom #> Approximate residual Deviance: 38.66  #> Number of Fisher scoring iterations:  4  #> Number of observations:  1681  #>   summary(update(house.mblogit.agg, dispersion = \"Afroz\")) #>  #> Call: #> mblogit(formula = Sat ~ Infl + Type + Cont, data = housing, weights = Freq,  #>     aggregate = TRUE) #>  #> Equation for Medium vs Low: #>               Estimate Std. Error t value Pr(>|t|)    #> (Intercept)    -0.4192     0.1832  -2.289  0.02842 *  #> InflMedium      0.4464     0.1499   2.977  0.00533 ** #> InflHigh        0.6649     0.1974   3.369  0.00189 ** #> TypeApartment  -0.4357     0.1827  -2.384  0.02284 *  #> TypeAtrium      0.1314     0.2363   0.556  0.58189    #> TypeTerrace    -0.6666     0.2184  -3.051  0.00440 ** #> ContHigh        0.3609     0.1402   2.573  0.01461 *  #>  #> Equation for High vs Low: #>               Estimate Std. Error t value Pr(>|t|)     #> (Intercept)    -0.1387     0.1686  -0.823 0.416418     #> InflMedium      0.7349     0.1450   5.067 1.41e-05 *** #> InflHigh        1.6126     0.1770   9.110 1.20e-10 *** #> TypeApartment  -0.7356     0.1645  -4.473 8.19e-05 *** #> TypeAtrium     -0.4080     0.2240  -1.821 0.077370 .   #> TypeTerrace    -1.4123     0.2120  -6.662 1.20e-07 *** #> ContHigh        0.4818     0.1315   3.665 0.000837 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Dispersion:  1.121765  on  34  degrees of freedom #> Approximate residual Deviance: 38.66  #> Number of Fisher scoring iterations:  4  #> Number of observations:  1681  #>   # If an estimate of the (over-)dispersion is requested, 'aggregate' is set to # TRUE by default: house.mblogit.odsp <- mblogit(Sat ~ Infl + Type + Cont,                                weights = Freq,                               data = housing,                                dispersion = \"Afroz\") #>  #> Iteration 1 - deviance = 38.84842 - criterion = 0.992521 #> Iteration 2 - deviance = 38.66222 - criterion = 0.004803721 #> Iteration 3 - deviance = 38.6622 - criterion = 3.782555e-07 #> Iteration 4 - deviance = 38.6622 - criterion = 3.666163e-15 #> converged summary(house.mblogit.odsp) #>  #> Call: #> mblogit(formula = Sat ~ Infl + Type + Cont, data = housing, weights = Freq,  #>     dispersion = \"Afroz\") #>  #> Equation for Medium vs Low: #>               Estimate Std. Error t value Pr(>|t|)    #> (Intercept)    -0.4192     0.1832  -2.289  0.02842 *  #> InflMedium      0.4464     0.1499   2.977  0.00533 ** #> InflHigh        0.6649     0.1974   3.369  0.00189 ** #> TypeApartment  -0.4357     0.1827  -2.384  0.02284 *  #> TypeAtrium      0.1314     0.2363   0.556  0.58189    #> TypeTerrace    -0.6666     0.2184  -3.051  0.00440 ** #> ContHigh        0.3609     0.1402   2.573  0.01461 *  #>  #> Equation for High vs Low: #>               Estimate Std. Error t value Pr(>|t|)     #> (Intercept)    -0.1387     0.1686  -0.823 0.416418     #> InflMedium      0.7349     0.1450   5.067 1.41e-05 *** #> InflHigh        1.6126     0.1770   9.110 1.20e-10 *** #> TypeApartment  -0.7356     0.1645  -4.473 8.19e-05 *** #> TypeAtrium     -0.4080     0.2240  -1.821 0.077370 .   #> TypeTerrace    -1.4123     0.2120  -6.662 1.20e-07 *** #> ContHigh        0.4818     0.1315   3.665 0.000837 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Dispersion:  1.121765  on  34  degrees of freedom #> Approximate residual Deviance: 38.66  #> Number of Fisher scoring iterations:  4  #> Number of observations:  1681  #>  dispersion(house.mblogit.odsp, method = \"Deviance\") #> [1] 1.137124  # Note that aggregation (either implicitly or explicitly required) affects # the reported deviance in surprising ways: house.mblogit.o.00 <- mblogit(Sat ~ Infl,                                weights = Freq,                               data = housing,                                dispersion = TRUE) #>  #> Iteration 1 - deviance = 2.084495e-10 - criterion = 0.01687143 #> Iteration 2 - deviance = 6.794565e-14 - criterion = 2.083815e-09 #> converged deviance(house.mblogit.o.00) #> [1] 6.794565e-14 dispersion(house.mblogit.o.00) #> [1] Inf # The deviance is (almost) zero, because aggregation leads to a two-way # table and a single-predictor model is already saturated.  # In order to make models comparable, one will need to set the groups: house.mblogit.o.0 <- mblogit(Sat ~ Infl,                               weights = Freq,                              data = housing,                               groups = ~ Infl + Type + Cont,                              dispersion = TRUE) #>  #> Iteration 1 - deviance = 111.578 - criterion = 0.9973916 #> Iteration 2 - deviance = 111.0847 - criterion = 0.004437062 #> Iteration 3 - deviance = 111.0846 - criterion = 5.432493e-07 #> Iteration 4 - deviance = 111.0846 - criterion = 9.969427e-15 #> converged deviance(house.mblogit.o.0) #> [1] 111.0846 dispersion(house.mblogit.o.0) #> [1] 2.567212  anova(house.mblogit.o.0,       house.mblogit.odsp) #> Analysis of Deviance Table #>  #> Model 1: Sat ~ Infl #> Model 2: Sat ~ Infl + Type + Cont #>   Resid. Df Resid. Dev Df Deviance #> 1        42    111.085             #> 2        34     38.662  8   72.422  # These complications with the deviances do not arrise if no aggregation is  # requested: house.mblogit.0 <- mblogit(Sat ~ Infl,                             weights = Freq,                            data = housing) #>  #> Iteration 1 - deviance = 3557.711 - criterion = 0.9621399 #> Iteration 2 - deviance = 3542.511 - criterion = 0.004290705 #> Iteration 3 - deviance = 3542.506 - criterion = 1.326243e-06 #> Iteration 4 - deviance = 3542.506 - criterion = 6.94199e-13 #> converged anova(house.mblogit.0,       house.mblogit) #> Analysis of Deviance Table #>  #> Model 1: Sat ~ Infl #> Model 2: Sat ~ Infl + Type + Cont #>   Resid. Df Resid. Dev Df Deviance #> 1       138     3542.5             #> 2       130     3470.1  8   72.422   # Using frequences on the left-hand side is perhaps the safest option: housing.wide <- memisc::Aggregate(table(Sat) ~ Infl + Type + Cont,                                   data = housing) # Note that 'Aggegate' uses                                                 # variable 'Freq' for weighting. house.mblogit.wide <- mblogit(cbind(Low,Medium,High) ~ Infl + Type + Cont,                                data = housing.wide) #>  #> Iteration 1 - deviance = 38.84842 - criterion = 0.992521 #> Iteration 2 - deviance = 38.66222 - criterion = 0.004803721 #> Iteration 3 - deviance = 38.6622 - criterion = 3.782555e-07 #> Iteration 4 - deviance = 38.6622 - criterion = 3.666163e-15 #> converged summary(house.mblogit.wide) #>  #> Call: #> mblogit(formula = cbind(Low, Medium, High) ~ Infl + Type + Cont,  #>     data = housing.wide) #>  #> Equation for Medium vs Low: #>               Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    -0.4192     0.1729  -2.424 0.015342 *   #> InflMedium      0.4464     0.1416   3.153 0.001613 **  #> InflHigh        0.6649     0.1863   3.568 0.000359 *** #> TypeApartment  -0.4357     0.1725  -2.525 0.011562 *   #> TypeAtrium      0.1314     0.2231   0.589 0.555980     #> TypeTerrace    -0.6666     0.2063  -3.232 0.001230 **  #> ContHigh        0.3609     0.1324   2.726 0.006420 **  #>  #> Equation for High vs Low: #>               Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    -0.1387     0.1592  -0.871 0.383570     #> InflMedium      0.7349     0.1369   5.366 8.03e-08 *** #> InflHigh        1.6126     0.1671   9.649  < 2e-16 *** #> TypeApartment  -0.7356     0.1553  -4.738 2.16e-06 *** #> TypeAtrium     -0.4080     0.2115  -1.929 0.053730 .   #> TypeTerrace    -1.4123     0.2001  -7.056 1.71e-12 *** #> ContHigh        0.4818     0.1241   3.881 0.000104 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Approximate residual Deviance: 38.66  #> Number of Fisher scoring iterations:  4  #> Number of observations:  24  #>  dispersion(house.mblogit.wide, method = \"Afroz\") #> [1] 1.121765  house.mblogit.wide.0 <- mblogit(cbind(Low,Medium,High) ~ Infl,                                  data = housing.wide) #>  #> Iteration 1 - deviance = 111.578 - criterion = 0.9973916 #> Iteration 2 - deviance = 111.0847 - criterion = 0.004437062 #> Iteration 3 - deviance = 111.0846 - criterion = 5.432493e-07 #> Iteration 4 - deviance = 111.0846 - criterion = 9.969427e-15 #> converged summary(house.mblogit.wide.0) #>  #> Call: #> mblogit(formula = cbind(Low, Medium, High) ~ Infl, data = housing.wide) #>  #> Equation for Medium vs Low: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  -0.5061     0.0971  -5.212 1.87e-07 *** #> InflMedium    0.4200     0.1399   3.002  0.00268 **  #> InflHigh      0.6026     0.1832   3.288  0.00101 **  #>  #> Equation for High vs Low: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept) -0.47712    0.09623  -4.958 7.12e-07 *** #> InflMedium   0.72519    0.13380   5.420 5.96e-08 *** #> InflHigh     1.54140    0.16213   9.507  < 2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Approximate residual Deviance: 111.1  #> Number of Fisher scoring iterations:  4  #> Number of observations:  24  #>  dispersion(house.mblogit.wide.0, method=\"Afroz\") #> [1] 2.567212  anova(house.mblogit.wide.0,       house.mblogit.wide) #> Analysis of Deviance Table #>  #> Model 1: cbind(Low, Medium, High) ~ Infl #> Model 2: cbind(Low, Medium, High) ~ Infl + Type + Cont #>   Resid. Df Resid. Dev Df Deviance #> 1        42    111.085             #> 2        34     38.662  8   72.422"},{"path":"https://melff.github.io/mclogit/reference/electors.html","id":null,"dir":"Reference","previous_headings":"","what":"Class, Party Position, and Electoral Choice — electors","title":"Class, Party Position, and Electoral Choice — electors","text":"artificial data set electoral choice influenced class party positions.","code":""},{"path":"https://melff.github.io/mclogit/reference/electors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Class, Party Position, and Electoral Choice — electors","text":"","code":"data(electors)"},{"path":"https://melff.github.io/mclogit/reference/electors.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Class, Party Position, and Electoral Choice — electors","text":"data frame containing following variables: class class position voters party party runs election Freq freqency party list chosen members class time time variable, runs zero one econ.left economic-policy \"leftness\" party welfare emphasis welfare expansion party auth position authoritarian issues","code":""},{"path":"https://melff.github.io/mclogit/reference/electors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Class, Party Position, and Electoral Choice — electors","text":"","code":"data(electors)  summary(mclogit(   cbind(Freq,interaction(time,class))~econ.left+welfare+auth,   data=electors)) #>  #> Iteration 1 - deviance = 85051.49 - criterion = 0.9989204 #> Iteration 2 - deviance = 76759.94 - criterion = 0.108019 #> Iteration 3 - deviance = 74896.56 - criterion = 0.02487934 #> Iteration 4 - deviance = 74890.9 - criterion = 7.559543e-05 #> Iteration 5 - deviance = 74890.9 - criterion = 1.726814e-09 #> converged #>  #> Call: #> mclogit(formula = cbind(Freq, interaction(time, class)) ~ econ.left +  #>     welfare + auth, data = electors) #>  #>            Estimate Std. Error z value Pr(>|z|)     #> econ.left -0.507265   0.007495 -67.679  < 2e-16 *** #> welfare    0.564650   0.010700  52.769  < 2e-16 *** #> auth       0.030305   0.005749   5.271 1.36e-07 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Null Deviance:     80580  #> Residual Deviance: 74890  #> Number of Fisher Scoring iterations:  5  #> Number of observations:  37500  #>  #>   summary(mclogit(   cbind(Freq,interaction(time,class))~econ.left/class+welfare/class+auth/class,   data=electors)) #>  #> Iteration 1 - deviance = 7377.939 - criterion = 0.9875551 #> Iteration 2 - deviance = 4589.544 - criterion = 0.6075407 #> Iteration 3 - deviance = 4293.485 - criterion = 0.06895374 #> Iteration 4 - deviance = 4277.887 - criterion = 0.00364612 #> Iteration 5 - deviance = 4277.808 - criterion = 1.852771e-05 #> Iteration 6 - deviance = 4277.808 - criterion = 5.890781e-10 #> converged #>  #> Call: #> mclogit(formula = cbind(Freq, interaction(time, class)) ~ econ.left/class +  #>     welfare/class + auth/class, data = electors) #>  #>                           Estimate Std. Error z value Pr(>|z|)     #> econ.left                 -0.77851    0.02312 -33.671  < 2e-16 *** #> welfare                    3.43776    0.03170 108.431  < 2e-16 *** #> auth                      -0.13740    0.03608  -3.808  0.00014 *** #> econ.left:classnew.middle  0.44546    0.02588  17.212  < 2e-16 *** #> econ.left:classold.middle -0.44082    0.10387  -4.244  2.2e-05 *** #> classnew.middle:welfare   -3.12917    0.03696 -84.659  < 2e-16 *** #> classold.middle:welfare   -5.27438    0.07286 -72.393  < 2e-16 *** #> classnew.middle:auth      -0.86676    0.03947 -21.957  < 2e-16 *** #> classold.middle:auth       1.39435    0.05615  24.831  < 2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Null Deviance:     80580  #> Residual Deviance: 4278  #> Number of Fisher Scoring iterations:  6  #> Number of observations:  37500  #>  #>   if (FALSE) # This takes a bit longer. summary(mclogit(   cbind(Freq,interaction(time,class))~econ.left/class+welfare/class+auth/class,   random=~1|party.time,   data=within(electors,party.time<-interaction(party,time))))  summary(mclogit(   cbind(Freq,interaction(time,class))~econ.left/(class*time)+welfare/class+auth/class,   random=~1|party.time,   data=within(electors,{         party.time <-interaction(party,time)         econ.left.sq <- (econ.left-mean(econ.left))^2         }))) #>  #> Iteration 1 - deviance = 1071.031 - criterion = 0.1597241 #> Iteration 2 - deviance = 965.6196 - criterion = 0.02540274 #> Iteration 3 - deviance = 948.8356 - criterion = 0.005154655 #> Iteration 4 - deviance = 947.6262 - criterion = 0.0002054859 #> Iteration 5 - deviance = 947.5081 - criterion = 2.557556e-07 #> Iteration 6 - deviance = 947.5042 - criterion = 4.672682e-13 #> converged #>  #> Call: #> mclogit(formula = cbind(Freq, interaction(time, class)) ~ econ.left/(class *  #>     time) + welfare/class + auth/class, data = within(electors,  #>     { #>         party.time <- interaction(party, time) #>         econ.left.sq <- (econ.left - mean(econ.left))^2 #>     }), random = ~1 | party.time) #>  #> Coefficents: #>                                Estimate Std. Error z value Pr(>|z|)     #> econ.left                      -0.13335    0.20837  -0.640    0.522     #> welfare                         2.05552    0.21245   9.675   <2e-16 *** #> auth                            0.08071    0.11717   0.689    0.491     #> econ.left:classnew.middle      -1.69581    0.11631 -14.580   <2e-16 *** #> econ.left:classold.middle      -3.04338    0.20351 -14.954   <2e-16 *** #> econ.left:time                 -0.07782    0.30228  -0.257    0.797     #> classnew.middle:welfare        -0.99267    0.06073 -16.346   <2e-16 *** #> classold.middle:welfare        -1.62088    0.12850 -12.614   <2e-16 *** #> classnew.middle:auth           -1.39056    0.04673 -29.754   <2e-16 *** #> classold.middle:auth            1.45722    0.05814  25.063   <2e-16 *** #> econ.left:classnew.middle:time  0.06049    0.14449   0.419    0.675     #> econ.left:classold.middle:time  0.14723    0.26232   0.561    0.575     #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Co-)Variances: #> Grouping level: party.time  #>          Estimate   Std.Err. #>          (Const.)   (Const.) #> (Const.)  1.604      0.3098  #>  #> Approximate residual deviance: 947.5  #> Number of Fisher scoring iterations:  6 #> Number of observations #>   Groups by party.time: 150 #>   Individual observations:  37500 #>   # \\dontrun{}"},{"path":"https://melff.github.io/mclogit/reference/getSummary-mclogit.html","id":null,"dir":"Reference","previous_headings":"","what":"`getSummary` Methods — getSummary-methods","title":"`getSummary` Methods — getSummary-methods","text":"getSummary methods use mtable","code":""},{"path":"https://melff.github.io/mclogit/reference/getSummary-mclogit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"`getSummary` Methods — getSummary-methods","text":"","code":"# S3 method for class 'mblogit' getSummary(obj,             alpha=.05,             ...) # S3 method for class 'mclogit' getSummary(obj,             alpha=.05,             rearrange=NULL,             ...) # S3 method for class 'mmblogit' getSummary(obj,             alpha=.05,             ...) # S3 method for class 'mmclogit' getSummary(obj,             alpha=.05,             rearrange=NULL,             ...)"},{"path":"https://melff.github.io/mclogit/reference/getSummary-mclogit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"`getSummary` Methods — getSummary-methods","text":"obj object returned mblogit mclogit alpha level confidence intervals; coverage     1-alpha/2 rearrange optional named list character vectors.       element list designates column table estimates,       element character vector refers coefficient.       Names list elements become column heads names       character vector elements become coefficient labels. ... arguments; ignored.","code":""},{"path":"https://melff.github.io/mclogit/reference/getSummary-mclogit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"`getSummary` Methods — getSummary-methods","text":"","code":"if (FALSE) { # \\dontrun{ summary(classd.model <- mclogit(cbind(Freq,choice.set)~                    (econdim1.sq+nonmatdim1.sq+nonmatdim2.sq)+                    (econdim1+nonmatdim1+nonmatdim2)+                    (econdim1+nonmatdim1+nonmatdim2):classd,                   data=mvoteint.classd,random=~1|mvoteint/eb,                   subset=classd!=\"Farmers\")) myGetSummary.classd <- function(x)getSummary.mclogit(x,rearrange=list(         \"Econ. Left/Right\"=c(                     \"Squared effect\"=\"econdim1.sq\",                     \"Linear effect\"=\"econdim1\",                     \" x Intermediate/Manual worker\"=\"econdim1:classdIntermediate\",                     \" x Service class/Manual worker\"=\"econdim1:classdService class\",                     \" x Self-employed/Manual worker\"=\"econdim1:classdSelf-employed\"                     ),         \"Lib./Auth.\"=c(                     \"Squared effect\"=\"nonmatdim1.sq\",                     \"Linear effect\"=\"nonmatdim1\",                     \" x Intermediate/Manual worker\"=\"nonmatdim1:classdIntermediate\",                     \" x Service class/Manual worker\"=\"nonmatdim1:classdService class\",                     \" x Self-employed/Manual worker\"=\"nonmatdim1:classdSelf-employed\"                     ),         \"Mod./Trad.\"=c(                     \"Squared effect\"=\"nonmatdim2.sq\",                     \"Linear effect\"=\"nonmatdim2\",                     \" x Intermediate/Manual worker\"=\"nonmatdim2:classdIntermediate\",                     \" x Service class/Manual worker\"=\"nonmatdim2:classdService class\",                     \" x Self-employed/Manual worker\"=\"nonmatdim2:classdSelf-employed\"                     )         ))  library(memisc) mtable(classd.model,getSummary=myGetSummary.classd) # Output would look like so: # ================================================================================== #                                 Econ. Left/Right    Lib./Auth.       Mod./Trad. # ---------------------------------------------------------------------------------- # Squared effect                      0.030            0.008           -0.129** #                                    (0.081)          (0.041)          (0.047) # Linear effect                      -0.583***        -0.038            0.137** #                                    (0.063)          (0.041)          (0.045) #  x Intermediate/Manual worker       0.632***        -0.029           -0.015 #                                    (0.026)          (0.020)          (0.019) #  x Service class/Manual worker      1.158***         0.084**          0.000 #                                    (0.040)          (0.032)          (0.030) #  x Self-employed/Manual worker      1.140***         0.363***         0.112*** #                                    (0.035)          (0.027)          (0.026) # Var(mvoteint)                       1.080*** #                                    (0.000) # Var(mvoteint x eb)                  0.118*** #                                    (0.000) # ---------------------------------------------------------------------------------- # Dispersion                              1.561 # Deviance                            15007.0 # N                                  173445 # ================================================================================== } # }"},{"path":"https://melff.github.io/mclogit/reference/mblogit.html","id":null,"dir":"Reference","previous_headings":"","what":"Baseline-Category Logit Models for Categorical and Multinomial Responses — mblogit","title":"Baseline-Category Logit Models for Categorical and Multinomial Responses — mblogit","text":"function mblogit fits baseline-category logit models categorical multinomial count responses fixed alternatives.","code":""},{"path":"https://melff.github.io/mclogit/reference/mblogit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Baseline-Category Logit Models for Categorical and Multinomial Responses — mblogit","text":"","code":"mblogit(   formula,   data = parent.frame(),   random = NULL,   catCov = c(\"free\", \"diagonal\", \"single\"),   subset,   weights = NULL,   offset = NULL,   na.action = getOption(\"na.action\"),   model = TRUE,   x = FALSE,   y = TRUE,   contrasts = NULL,   method = NULL,   estimator = c(\"ML\", \"REML\"),   dispersion = FALSE,   start = NULL,   aggregate = !isFALSE(dispersion),   groups = NULL,   from.table = FALSE,   control = if (length(random)) mmclogit.control(...) else mclogit.control(...),   ... )"},{"path":"https://melff.github.io/mclogit/reference/mblogit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Baseline-Category Logit Models for Categorical and Multinomial Responses — mblogit","text":"formula model formula. response must factor matrix counts. data optional data frame, list environment (object coercible .data.frame data frame) containing variables model.  found data, variables taken environment(formula), typically environment glm called. random optional formula list formulas specify random-effects structure NULL. catCov character string specifies optional restrictions covariances random effects logit equations. \"free\" means restrictions, \"diagonal\" means random effects pertinent different categories uncorrelated, \"single\" means random effect variances pertinent categories identical. subset optional vector specifying subset observations used fitting process. weights optional vector weights used fitting process.  NULL numeric vector. offset optional model offset. NULL, must matrix many columns response categories one less. na.action function indicates happen data contain NAs.  default set na.action setting options, na.fail unset. ‘factory-fresh’ default na.omit.  Another possible value NULL, action.  Value na.exclude can useful. model logical value indicating whether model frame included component returned value. x, y logical values indicating whether response vector model matrix used fitting process returned components returned value. contrasts optional list. See contrasts.arg model.matrix.default. method NULL character string, either \"PQL\" \"MQL\", specifies type quasilikelihood approximation used random-effects model estimated. estimator character string; either \"ML\" \"REML\", specifies estimator used/approximated. dispersion logical value character string; whether dispersion parameter estimated. details see dispersion. start optional matrix starting values (many rows logit equations). model random effects, matrix \"VarCov\" attribute wtih starting values random effects (co-)variances. random effects model estimated \"PQL\" method, starting values matrix also \"random.effects\" attribute, structure \"random.effects\" component object returned mblogit(). aggregate logical value; whether aggregate responses covariate classes groups estimating model response variable factor. affect estimates, dispersion residual degrees freedom. aggregate=TRUE, dispersion relative saturated model; much smaller aggregate=TRUE. particular, single covariate grouping, deviance close zero. dispersion FALSE, default value aggregate TRUE. details see dispersion. argument consequences response formula factor. groups optional formula specifies groups observations relevant estimation overdispersion. details see dispersion. .table logical value; FALSE. argument exists sake compatibility removed next relase. control list parameters fitting process.  See mclogit.control ... arguments passed mclogit.control mmclogit.control","code":""},{"path":"https://melff.github.io/mclogit/reference/mblogit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Baseline-Category Logit Models for Categorical and Multinomial Responses — mblogit","text":"mblogit returns object class \"mblogit\", almost     structure object class \"glm\".     difference components coefficients, residuals,     fitted.values, linear.predictors, y,     matrices number columns equal number response     categories minus one.","code":""},{"path":"https://melff.github.io/mclogit/reference/mblogit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Baseline-Category Logit Models for Categorical and Multinomial Responses — mblogit","text":"function mblogit internally rearranges data     'long' format uses mclogit.fit compute     estimates. Nevertheless, 'user data' unaffected.","code":""},{"path":"https://melff.github.io/mclogit/reference/mblogit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Baseline-Category Logit Models for Categorical and Multinomial Responses — mblogit","text":"Agresti, Alan. 2002.    Categorical Data Analysis. 2nd ed, Hoboken, NJ: Wiley.    doi:10.1002/0471249688 Breslow, N.E. D.G. Clayton. 1993.    \"Approximate Inference Generalized Linear Mixed Models\".    Journal American Statistical Association 88 (421): 9-25.    doi:10.1080/01621459.1993.10594284","code":""},{"path":[]},{"path":"https://melff.github.io/mclogit/reference/mblogit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Baseline-Category Logit Models for Categorical and Multinomial Responses — mblogit","text":"","code":"library(MASS) # For 'housing' data library(nnet) library(memisc) #> Loading required package: lattice #>  #> Attaching package: ‘memisc’ #> The following object is masked from ‘package:Matrix’: #>  #>     as.array #> The following objects are masked from ‘package:stats’: #>  #>     contr.sum, contr.treatment, contrasts #> The following object is masked from ‘package:base’: #>  #>     as.array  (house.mult<- multinom(Sat ~ Infl + Type + Cont, weights = Freq,                        data = housing)) #> # weights:  24 (14 variable) #> initial  value 1846.767257  #> iter  10 value 1747.045232 #> final  value 1735.041933  #> converged #> Call: #> multinom(formula = Sat ~ Infl + Type + Cont, data = housing,  #>     weights = Freq) #>  #> Coefficients: #>        (Intercept) InflMedium  InflHigh TypeApartment TypeAtrium TypeTerrace #> Medium  -0.4192316  0.4464003 0.6649367    -0.4356851  0.1313663  -0.6665728 #> High    -0.1387453  0.7348626 1.6126294    -0.7356261 -0.4079808  -1.4123333 #>         ContHigh #> Medium 0.3608513 #> High   0.4818236 #>  #> Residual Deviance: 3470.084  #> AIC: 3498.084    (house.mblogit <- mblogit(Sat ~ Infl + Type + Cont, weights = Freq,                          data = housing)) #>  #> Iteration 1 - deviance = 3493.764 - criterion = 0.9614469 #> Iteration 2 - deviance = 3470.111 - criterion = 0.00681597 #> Iteration 3 - deviance = 3470.084 - criterion = 7.82437e-06 #> Iteration 4 - deviance = 3470.084 - criterion = 7.469596e-11 #> converged #>  #> Call: mblogit(formula = Sat ~ Infl + Type + Cont, data = housing, weights = Freq) #>  #> Coefficients: #>             Predictors #> Logit eqn.    (Intercept)  InflMedium  InflHigh  TypeApartment  TypeAtrium #>   Medium/Low  -0.4192       0.4464      0.6649   -0.4357         0.1314    #>   High/Low    -0.1387       0.7349      1.6126   -0.7356        -0.4080    #>             Predictors #> Logit eqn.    TypeTerrace  ContHigh #>   Medium/Low  -0.6666       0.3609  #>   High/Low    -1.4123       0.4818  #>  #> Null Deviance:     3694  #> Residual Deviance: 3470  summary(house.mult) #> Call: #> multinom(formula = Sat ~ Infl + Type + Cont, data = housing,  #>     weights = Freq) #>  #> Coefficients: #>        (Intercept) InflMedium  InflHigh TypeApartment TypeAtrium TypeTerrace #> Medium  -0.4192316  0.4464003 0.6649367    -0.4356851  0.1313663  -0.6665728 #> High    -0.1387453  0.7348626 1.6126294    -0.7356261 -0.4079808  -1.4123333 #>         ContHigh #> Medium 0.3608513 #> High   0.4818236 #>  #> Std. Errors: #>        (Intercept) InflMedium  InflHigh TypeApartment TypeAtrium TypeTerrace #> Medium   0.1729344  0.1415572 0.1863374     0.1725327  0.2231065   0.2062532 #> High     0.1592295  0.1369380 0.1671316     0.1552714  0.2114965   0.2001496 #>         ContHigh #> Medium 0.1323975 #> High   0.1241371 #>  #> Residual Deviance: 3470.084  #> AIC: 3498.084   summary(house.mblogit) #>  #> Call: #> mblogit(formula = Sat ~ Infl + Type + Cont, data = housing, weights = Freq) #>  #> Equation for Medium vs Low: #>               Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    -0.4192     0.1729  -2.424 0.015342 *   #> InflMedium      0.4464     0.1416   3.153 0.001613 **  #> InflHigh        0.6649     0.1863   3.568 0.000359 *** #> TypeApartment  -0.4357     0.1725  -2.525 0.011562 *   #> TypeAtrium      0.1314     0.2231   0.589 0.555980     #> TypeTerrace    -0.6666     0.2063  -3.232 0.001230 **  #> ContHigh        0.3609     0.1324   2.726 0.006420 **  #>  #> Equation for High vs Low: #>               Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    -0.1387     0.1592  -0.871 0.383570     #> InflMedium      0.7349     0.1369   5.366 8.03e-08 *** #> InflHigh        1.6126     0.1671   9.649  < 2e-16 *** #> TypeApartment  -0.7356     0.1553  -4.738 2.16e-06 *** #> TypeAtrium     -0.4080     0.2115  -1.929 0.053730 .   #> TypeTerrace    -1.4123     0.2001  -7.056 1.71e-12 *** #> ContHigh        0.4818     0.1241   3.881 0.000104 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Approximate residual Deviance: 3470  #> Number of Fisher scoring iterations:  4  #> Number of observations:  1681  #>   mtable(house.mblogit) #>  #> Calls: #> house.mblogit: mblogit(formula = Sat ~ Infl + Type + Cont, data = housing, weights = Freq) #>  #> ================================================ #>                          Medium/Low  High/Low    #> ------------------------------------------------ #>   (Intercept)              -0.419*   -0.139      #>                            (0.173)   (0.159)     #>   Infl: Medium/Low          0.446**   0.735***   #>                            (0.142)   (0.137)     #>   Infl: High/Low            0.665***  1.613***   #>                            (0.186)   (0.167)     #>   Type: Apartment/Tower    -0.436*   -0.736***   #>                            (0.173)   (0.155)     #>   Type: Atrium/Tower        0.131    -0.408      #>                            (0.223)   (0.211)     #>   Type: Terrace/Tower      -0.667**  -1.412***   #>                            (0.206)   (0.200)     #>   Cont: High/Low            0.361**   0.482***   #>                            (0.132)   (0.124)     #> ------------------------------------------------ #>   Deviance               3470.1                  #>   N                      1681                    #> ================================================ #>   Significance: *** = p < 0.001;    #>                 ** = p < 0.01; * = p < 0.05"},{"path":"https://melff.github.io/mclogit/reference/mclogit.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal functions used for model fit. — mclogit.fit","title":"Internal functions used for model fit. — mclogit.fit","text":"functions exported documented use packages.   intended end users.","code":""},{"path":"https://melff.github.io/mclogit/reference/mclogit.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal functions used for model fit. — mclogit.fit","text":"","code":"mclogit.fit(y, s, w, X,             dispersion=FALSE,             start = NULL, offset = NULL,             control = mclogit.control())  mmclogit.fitPQLMQL(y, s, w, X, Z, d,                     start = NULL,                    start.Phi = NULL,                    start.b = NULL,                    offset = NULL, method=c(\"PQL\",\"MQL\"),                    estimator = c(\"ML\",\"REML\"),                    control = mmclogit.control())"},{"path":"https://melff.github.io/mclogit/reference/mclogit.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal functions used for model fit. — mclogit.fit","text":"y response vector. binary. s vector identifying individuals covariate strata w vector observation weights. X model matrix; required. dispersion logical value character string; whether      dispersion parameter estimated. details see dispersion. Z random effects design matrix. d dimension random effects. Typically $d=1$ random intercepts   , $d>1$ models random intercepts. start optional numerical vector starting values     coefficients. offset optional model offset. Currently supported     models without random effects. start.Phi optional matrix strarting values     (co-)variance parameters. start.b optional list vectors starting values     random effects. method character string, either \"PQL\" \"MQL\", specifies     type quasilikelihood approximation. estimator character string; either \"ML\" \"REML\",     specifies estimator used/approximated. control list parameters fitting process.     See mclogit.control","code":""},{"path":"https://melff.github.io/mclogit/reference/mclogit.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal functions used for model fit. — mclogit.fit","text":"list components describing fitted model.","code":""},{"path":"https://melff.github.io/mclogit/reference/mclogit.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional Logit Models and Mixed Conditional Logit Models — mclogit","title":"Conditional Logit Models and Mixed Conditional Logit Models — mclogit","text":"mclogit fits conditional logit models mixed conditional   logit models count data individual choice data,   choice set may vary across choice occasions. Conditional logit models without random effects fitted   Fisher-scoring/IWLS. Models random effects   (mixed conditional logit models) estimated via maximum likelihood   simple Laplace aproximation (aka PQL).","code":""},{"path":"https://melff.github.io/mclogit/reference/mclogit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Logit Models and Mixed Conditional Logit Models — mclogit","text":"","code":"mclogit(formula, data=parent.frame(), random=NULL,         subset, weights = NULL, offset=NULL, na.action = getOption(\"na.action\"),         model = TRUE, x = FALSE, y = TRUE, contrasts=NULL,         method = NULL, estimator=c(\"ML\",\"REML\"),         dispersion = FALSE,         start=NULL,         groups = NULL,         control=if(length(random))                     mmclogit.control(...)                 else mclogit.control(...), ...)  # S3 method for class 'mclogit' update(object, formula., dispersion, ...)  # S3 method for class 'mclogit' summary(object, dispersion = NULL, correlation = FALSE,         symbolic.cor = FALSE,  ...)"},{"path":"https://melff.github.io/mclogit/reference/mclogit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Logit Models and Mixed Conditional Logit Models — mclogit","text":"formula model formula: symbolic description     model fitted. left-hand side result     two-column matrix. first column contains     choice counts choice indicators (alternative     chosen=1, chosen=0). second column contains     unique numbers choice set. left-hand side can either take form cbind(choice,set)     (version 0.9.1) choice|set individual-level data used, choice sets correspond     individuals, aggregated data choice counts used,     choice sets usually correspond covariate classes. right-hand formula contains choice predictors. noted     constants deleted formula predictors vary     within choice sets. data optional data frame, list environment (object     coercible .data.frame data frame) containing     variables model.  found data,     variables taken environment(formula),     typically environment glm called. random optional formula list formulas specify     random-effects structure NULL. subset optional vector specifying subset observations     used fitting process. weights optional vector weights used fitting     process.  NULL numeric vector. offset optional model offset. na.action function indicates happen     data contain NAs.  default set     na.action setting options,     na.fail unset.  ‘factory-fresh’     default na.omit.  Another possible value     NULL, action.  Value na.exclude can useful. start optional numerical vector starting values     conditional logit parameters.  model random effects,     vector \"VarCov\" attribute wtih starting values     random effects (co-)variances. random effects model     estimated \"PQL\" method, starting values matrix     also \"random.effects\" attribute,     structure \"random.effects\" component object returned     mblogit(). model logical value indicating whether model frame     included component returned value. x, y logical values indicating whether response vector model     matrix used fitting process returned components     returned value. contrasts optional list. See contrasts.arg     model.matrix.default. method NULL character string, either \"PQL\" \"MQL\", specifies       type quasilikelihood approximation used       random-effects model estimated. estimator character string; either \"ML\" \"REML\",     specifies estimator used/approximated. dispersion real number used dispersion parameter;     character vector specifies method compute dispersion;     logical value – TRUE default method     (\"Afroz\") used, FALSE, dispersion parameter     set 1, , dispersion. details see dispersion. groups optional formula specifies groups observations     relevant estimation overdispersion. Covariates     constant within groups, otherwise warning generated     since overdispersion estimate may     imprecise. control list parameters fitting process.     See mclogit.control ... arguments passed mclogit.control mmclogit.control object object inherits class \"mclogit\".     passed dispersion(),     result call mclogit()     mblogit(), without random effects. formula. changes model formula,     see update.default     update.formula. correlation logical; see summary.lm. symbolic.cor logical; see summary.lm.","code":""},{"path":"https://melff.github.io/mclogit/reference/mclogit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional Logit Models and Mixed Conditional Logit Models — mclogit","text":"mclogit returns object class \"mclogit\", almost   structure object class \"glm\".","code":""},{"path":"https://melff.github.io/mclogit/reference/mclogit.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Conditional Logit Models and Mixed Conditional Logit Models — mclogit","text":"Covariates constant within choice sets automatically   dropped model formula specified formula   argument mclogit. model contains random effects, either vary within choice sets (e.g. levels factor     defines choice sets nested within levels     factor) random coefficients covariates vary within     choice sets. earlier versions package (prior 0.6) lead   failure model fitting algorithm conditions   satisfied. Since version 0.6 package, function   mclogit complain model misspecification   explicitely. version 0.9.7 possible choose optimization   technique used inner iterations PQL/MQL: either   nlminb (default), nlm,   algorithms (\"Brent\" supported   optim).  choose optimizer, use   appropriate argument mmclogit.control .","code":""},{"path":"https://melff.github.io/mclogit/reference/mclogit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conditional Logit Models and Mixed Conditional Logit Models — mclogit","text":"Agresti, Alan (2002).     Categorical Data Analysis. 2nd ed, Hoboken, NJ: Wiley.     doi:10.1002/0471249688 Breslow, N.E. D.G. Clayton (1993).     \"Approximate Inference Generalized Linear Mixed Models\".     Journal American Statistical Association 88 (421): 9-25.     doi:10.1080/01621459.1993.10594284 Elff, Martin (2009).     \"Social Divisions, Party Positions, Electoral Behaviour\".     Electoral Studies 28(2): 297-308.     doi:10.1016/j.electstud.2009.02.002 McFadden, D. (1973).     \"Conditionial Logit Analysis Qualitative Choice Behavior\".     Pp. 105-135 P. Zarembka (ed.).     Frontiers Econometrics.     New York: Wiley.     https://eml.berkeley.edu/reprints/mcfadden/zarembka.pdf","code":""},{"path":[]},{"path":"https://melff.github.io/mclogit/reference/mclogit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional Logit Models and Mixed Conditional Logit Models — mclogit","text":"","code":"data(Transport)  summary(mclogit(   cbind(resp,suburb)~distance+cost,   data=Transport   )) #>  #> Iteration 1 - deviance = 39.74973 - criterion = 0.8590917 #> Iteration 2 - deviance = 10.50328 - criterion = 2.758244 #> Iteration 3 - deviance = 9.231325 - criterion = 0.1363107 #> Iteration 4 - deviance = 9.227742 - criterion = 0.0003840654 #> Iteration 5 - deviance = 9.227742 - criterion = 3.446459e-09 #> converged #>  #> Call: #> mclogit(formula = cbind(resp, suburb) ~ distance + cost, data = Transport) #>  #>          Estimate Std. Error z value Pr(>|z|)     #> distance -1.43940    0.05318  -27.07   <2e-16 *** #> cost     -0.97753    0.03987  -24.52   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Null Deviance:     2734  #> Residual Deviance: 9.228  #> Number of Fisher Scoring iterations:  5  #> Number of observations:  1994  #>  #>  # New syntactic sugar: summary(mclogit(   resp|suburb~distance+cost,   data=Transport   )) #>  #> Iteration 1 - deviance = 39.74973 - criterion = 0.8590917 #> Iteration 2 - deviance = 10.50328 - criterion = 2.758244 #> Iteration 3 - deviance = 9.231325 - criterion = 0.1363107 #> Iteration 4 - deviance = 9.227742 - criterion = 0.0003840654 #> Iteration 5 - deviance = 9.227742 - criterion = 3.446459e-09 #> converged #>  #> Call: #> mclogit(formula = resp | suburb ~ distance + cost, data = Transport) #>  #>          Estimate Std. Error z value Pr(>|z|)     #> distance -1.43940    0.05318  -27.07   <2e-16 *** #> cost     -0.97753    0.03987  -24.52   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Null Deviance:     2734  #> Residual Deviance: 9.228  #> Number of Fisher Scoring iterations:  5  #> Number of observations:  1994  #>  #>    if (FALSE)  # This takes a bit longer. data(electors)  electors <- within(electors,{     party.time <-interaction(party,time)     time.class <- interaction(time,class) })  # Time points nested within parties summary(mclogit(   Freq|time.class~econ.left/class+welfare/class+auth/class,   random=~1|party/time,   data=electors)) #>  #> Warning: Possible non-convergence of inner iterations - nlminb message: singular convergence (7) #>  #> Iteration 1 - deviance = 495.6469 - criterion = 0.1640698 #> Iteration 2 - deviance = 379.0387 - criterion = 0.02944294 #> Iteration 3 - deviance = 363.3644 - criterion = 0.006445485 #> Iteration 4 - deviance = 362.7738 - criterion = 0.0003382211 #> Iteration 5 - deviance = 362.7685 - criterion = 6.930491e-07 #> Iteration 6 - deviance = 362.7684 - criterion = 2.672469e-12 #> converged #>  #> Call: #> mclogit(formula = Freq | time.class ~ econ.left/class + welfare/class +  #>     auth/class, data = electors, random = ~1 | party/time) #>  #> Coefficents: #>                           Estimate Std. Error z value Pr(>|z|)     #> econ.left                 -0.04035    0.73004  -0.055   0.9559     #> welfare                    1.95936    1.16585   1.681   0.0928 .   #> auth                       0.16811    0.62796   0.268   0.7889     #> econ.left:classnew.middle -2.04700    0.11816 -17.324   <2e-16 *** #> econ.left:classold.middle -3.39457    0.17416 -19.491   <2e-16 *** #> classnew.middle:welfare   -0.75181    0.07501 -10.023   <2e-16 *** #> classold.middle:welfare   -1.27119    0.14517  -8.757   <2e-16 *** #> classnew.middle:auth      -1.49715    0.05188 -28.855   <2e-16 *** #> classold.middle:auth       1.40982    0.05997  23.510   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Co-)Variances: #> Grouping level: party  #>          Estimate   Std.Err. #>          (Const.)   (Const.) #> (Const.)  2.002      2.143   #>  #> Grouping level: party:time  #>          Estimate    Std.Err. #>          (Const.)    (Const.) #> (Const.) 2.372e-08   1.09e-24 #>  #> Approximate residual deviance: 362.8  #> Number of Fisher scoring iterations:  6 #> Number of observations #>   Groups by party: 6 #>   Groups by party:time: 150 #>   Individual observations:  37500 #>   # Party-level random intercepts and random slopes varying over time points summary(mclogit(   Freq|time.class~econ.left/class+welfare/class+auth/class,   random=list(~1|party,~econ.left+0|time),   data=electors)) #>  #> Iteration 1 - deviance = 495.6162 - criterion = 0.1640703 #> Iteration 2 - deviance = 378.9601 - criterion = 0.02945638 #> Iteration 3 - deviance = 363.1957 - criterion = 0.006453599 #> Iteration 4 - deviance = 362.5831 - criterion = 0.0003390485 #> Iteration 5 - deviance = 362.5743 - criterion = 6.960937e-07 #> Iteration 6 - deviance = 362.574 - criterion = 2.692628e-12 #> converged #>  #> Call: #> mclogit(formula = Freq | time.class ~ econ.left/class + welfare/class +  #>     auth/class, data = electors, random = list(~1 | party, ~econ.left +  #>     0 | time)) #>  #> Coefficents: #>                           Estimate Std. Error z value Pr(>|z|)     #> econ.left                 -0.04034    0.73006  -0.055   0.9559     #> welfare                    1.95937    1.16587   1.681   0.0928 .   #> auth                       0.16811    0.62797   0.268   0.7889     #> econ.left:classnew.middle -2.04703    0.11816 -17.324   <2e-16 *** #> econ.left:classold.middle -3.39462    0.17416 -19.492   <2e-16 *** #> classnew.middle:welfare   -0.75181    0.07501 -10.023   <2e-16 *** #> classold.middle:welfare   -1.27119    0.14517  -8.757   <2e-16 *** #> classnew.middle:auth      -1.49715    0.05188 -28.855   <2e-16 *** #> classold.middle:auth       1.40982    0.05997  23.510   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Co-)Variances: #> Grouping level: party  #>          Estimate   Std.Err. #>          (Const.)   (Const.) #> (Const.)  2.002      2.143   #>  #> Grouping level: time  #>           Estimate    Std.Err.  #>           econ.left   econ.left #> econ.left 0.0002345   2.579e-12 #>  #> Approximate residual deviance: 362.6  #> Number of Fisher scoring iterations:  6 #> Number of observations #>   Groups by party: 6 #>   Groups by time: 25 #>   Individual observations:  37500 #>   # \\dontrun{}"},{"path":"https://melff.github.io/mclogit/reference/mclogit_control.html","id":null,"dir":"Reference","previous_headings":"","what":"Control Parameters for the Fitting Process — mclogit.control","title":"Control Parameters for the Fitting Process — mclogit.control","text":"mclogit.control returns list default parameters   control fitting process mclogit.","code":""},{"path":"https://melff.github.io/mclogit/reference/mclogit_control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control Parameters for the Fitting Process — mclogit.control","text":"","code":"mclogit.control(epsilon = 1e-08,                 maxit = 25, trace=TRUE) mmclogit.control(epsilon = 1e-08,                  maxit = 25, trace=TRUE,                  trace.inner=FALSE,                  avoid.increase = FALSE,                  break.on.increase = FALSE,                  break.on.infinite = FALSE,                  break.on.negative = FALSE,                  inner.optimizer = \"nlminb\",                  maxit.inner = switch(inner.optimizer,                                       SANN          = 10000,                                       `Nelder-Mead` = 500,                                       100),                  CG.type = 1,                  NM.alpha = 1,                  NM.beta = 0.5,                  NM.gamma = 2.0,                  SANN.temp = 10,                  SANN.tmax = 10,                  grtol = 1e-6,                  xtol = 1e-8,                  maxeval = 100,                  gradstep = c(1e-6, 1e-8),                  use.gradient = c(\"analytic\",\"numeric\"))"},{"path":"https://melff.github.io/mclogit/reference/mclogit_control.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control Parameters for the Fitting Process — mclogit.control","text":"epsilon positive convergence tolerance \\(\\epsilon\\);     iterations converge     \\(|dev - dev_{old}|/(|dev| + 0.1) < \\epsilon\\). maxit integer giving maximal number IWLS PQL iterations. trace logical indicating output produced     iteration. trace.inner logical; indicating output produced      inner iteration PQL method. avoid.increase logical; increase deviance      avoided step truncation? break..increase logical; increase deviance      avoided stopping algorithm? break..infinite logical; infinite deviance      stop algorithm instead leading step truncation? break..negative logical; negative deviance      stop algorithm? inner.optimizer character string, one      \"nlminb\", \"nlm\", \"ucminf\", \"Nelder-Mead\", \"BFGS\", \"CG\", \"L-BFGS-B\", \"SANN\".      See nlminb, nlm,      ucminf,      optim. maxit.inner integer; maximum number inner iterations CG.type integer; type argument passed      optim      \"CG\" selected inner optimizer. NM.alpha integer; alpha argument passed      optim      \"Nelder-Mead\" selected inner optimizer. NM.beta integer; beta argument passed      optim      \"Nelder-Mead\" selected inner optimizer. NM.gamma integer; gamma argument passed      optim      \"Nelder-Mead\" selected inner optimizer. SANN.temp integer; temp argument passed      optim      \"SANN\" selected inner optimizer. SANN.tmax integer; tmax argument passed      optim      \"SANN\" selected inner optimizer. grtol numeric; grtol control parameter      ucminf \"ucminf\" selected inner optimizer. xtol numeric; xtol control parameter      ucminf \"ucminf\" selected inner optimizer. maxeval integer; maxeval control parameter      ucminf \"ucminf\" selected inner optimizer. gradstep numeric vector length; gradstep control parameter      ucminf \"ucminf\" selected inner optimizer. use.gradient character string; whether gradient      computed analytically whether finite-difference approximation      used.","code":""},{"path":"https://melff.github.io/mclogit/reference/mclogit_control.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control Parameters for the Fitting Process — mclogit.control","text":"list.","code":""},{"path":"https://melff.github.io/mclogit/reference/predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Predicting responses or linear parts of the baseline-category and conditional logit models — predict","title":"Predicting responses or linear parts of the baseline-category and conditional logit models — predict","text":"predict() methods allow obtain within-sample   --sample predictions models   fitted mclogit() mblogit(). models random effecs fitted using PQL-method,   possible obtain responses conditional reconstructed   random effects.","code":""},{"path":"https://melff.github.io/mclogit/reference/predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predicting responses or linear parts of the baseline-category and conditional logit models — predict","text":"","code":"# S3 method for class 'mblogit' predict(object, newdata=NULL,type=c(\"link\",\"response\"),se.fit=FALSE, ...) # S3 method for class 'mclogit' predict(object, newdata=NULL,type=c(\"link\",\"response\"),se.fit=FALSE, ...) # S3 method for class 'mmblogit' predict(object, newdata=NULL,type=c(\"link\",\"response\"),se.fit=FALSE,                              conditional=TRUE, ...) # S3 method for class 'mmclogit' predict(object, newdata=NULL,type=c(\"link\",\"response\"),se.fit=FALSE,                              conditional=TRUE, ...)"},{"path":"https://melff.github.io/mclogit/reference/predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predicting responses or linear parts of the baseline-category and conditional logit models — predict","text":"object object class \"mblogit\", \"mmblogit\", \"mclogit\",    \"mmclogit\" newdata optional data frame new data type character string specifying kind prediction se.fit logical value; whether predictions    accompanied standard errors conditional logical value; whether predictions made    conditional random effects (whether set zero,    .e. expectation). argument consequential    \"mmblogit\" \"mmclogit\" object created method=\"PQL\". ... arguments, ignored.","code":""},{"path":"https://melff.github.io/mclogit/reference/predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predicting responses or linear parts of the baseline-category and conditional logit models — predict","text":"predict methods return either matrix (unless called   se.fit=TRUE) list two matrix-valued elements   \"fit\" \"se.fit\".","code":""},{"path":"https://melff.github.io/mclogit/reference/predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predicting responses or linear parts of the baseline-category and conditional logit models — predict","text":"","code":"library(MASS) (house.mblogit <- mblogit(Sat ~ Infl + Type + Cont,                            data = housing,                           weights=Freq)) #>  #> Iteration 1 - deviance = 3493.764 - criterion = 0.9614469 #> Iteration 2 - deviance = 3470.111 - criterion = 0.00681597 #> Iteration 3 - deviance = 3470.084 - criterion = 7.82437e-06 #> Iteration 4 - deviance = 3470.084 - criterion = 7.469596e-11 #> converged #>  #> Call: mblogit(formula = Sat ~ Infl + Type + Cont, data = housing, weights = Freq) #>  #> Coefficients: #>             Predictors #> Logit eqn.    (Intercept)  InflMedium  InflHigh  TypeApartment  TypeAtrium #>   Medium/Low  -0.4192       0.4464      0.6649   -0.4357         0.1314    #>   High/Low    -0.1387       0.7349      1.6126   -0.7356        -0.4080    #>             Predictors #> Logit eqn.    TypeTerrace  ContHigh #>   Medium/Low  -0.6666       0.3609  #>   High/Low    -1.4123       0.4818  #>  #> Null Deviance:     3694  #> Residual Deviance: 3470  head(pred.house.mblogit <- predict(house.mblogit)) #>        Medium       High #> 1 -0.41922874 -0.1387428 #> 2 -0.41922874 -0.1387428 #> 3 -0.41922874 -0.1387428 #> 4  0.02716715  0.5961205 #> 5  0.02716715  0.5961205 #> 6  0.02716715  0.5961205 str(pred.house.mblogit <- predict(house.mblogit,se=TRUE)) #> List of 2 #>  $ fit   : num [1:72, 1:2] -0.4192 -0.4192 -0.4192 0.0272 0.0272 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:72] \"1\" \"2\" \"3\" \"4\" ... #>   .. ..$ : chr [1:2] \"Medium\" \"High\" #>  $ se.fit: num [1:72, 1:2] 0.173 0.173 0.173 0.17 0.17 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:2] \"Medium\" \"High\"  head(pred.house.mblogit <- predict(house.mblogit,                                    type=\"response\")) #>         Low    Medium      High #> 1 0.3955687 0.2601077 0.3443236 #> 2 0.3955687 0.2601077 0.3443236 #> 3 0.3955687 0.2601077 0.3443236 #> 4 0.2602403 0.2674072 0.4723526 #> 5 0.2602403 0.2674072 0.4723526 #> 6 0.2602403 0.2674072 0.4723526 str(pred.house.mblogit <- predict(house.mblogit,se=TRUE,                                   type=\"response\")) #> List of 2 #>  $ fit   : num [1:72, 1:3] 0.396 0.396 0.396 0.26 0.26 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:72] \"1\" \"2\" \"3\" \"4\" ... #>   .. ..$ : chr [1:3] \"Low\" \"Medium\" \"High\" #>  $ se.fit: num [1:72, 1:3] 0.0343 0.0343 0.0343 0.0273 0.0273 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:72] \"1\" \"2\" \"3\" \"4\" ... #>   .. ..$ : chr [1:3] \"Low\" \"Medium\" \"High\"  # This takes a bit longer. data(electors) (mcre <- mclogit(     cbind(Freq,interaction(time,class))~econ.left/class+welfare/class+auth/class,     random=~1|party.time,     data=within(electors,party.time<-interaction(party,time)))) #>  #> Iteration 1 - deviance = 1070.463 - criterion = 0.1596265 #> Iteration 2 - deviance = 965.7808 - criterion = 0.0253941 #> Iteration 3 - deviance = 949.163 - criterion = 0.005112973 #> Iteration 4 - deviance = 947.9638 - criterion = 0.0002016051 #> Iteration 5 - deviance = 947.8468 - criterion = 2.469648e-07 #> Iteration 6 - deviance = 947.8431 - criterion = 4.94197e-13 #> converged #> mclogit(formula = cbind(Freq, interaction(time, class)) ~ econ.left/class +  #>     welfare/class + auth/class, data = within(electors, party.time <- interaction(party,  #>     time)), random = ~1 | party.time) #>  #> Coefficients: #>                 econ.left                    welfare   #>                  -0.17380                    2.05525   #>                      auth  econ.left:classnew.middle   #>                   0.08059                   -1.66428   #> econ.left:classold.middle    classnew.middle:welfare   #>                  -2.96667                   -0.99252   #>   classold.middle:welfare       classnew.middle:auth   #>                  -1.62032                   -1.39064   #>      classold.middle:auth   #>                   1.45728   #>  #> (Co-)Variances: #> Grouping level: party.time  #>           (Const.) #> (Const.)  1.604    #>  #> Approximate residual deviance: 947.8  str(predict(mcre)) #>  num [1:450] 1.168 4.367 0.148 -1.285 -1.378 ... str(predict(mcre,type=\"response\")) #>  num [1:450] 0.03789 0.92862 0.01366 0.00326 0.00297 ...  str(predict(mcre,se.fit=TRUE)) #> List of 2 #>  $ fit   : num [1:450] 1.168 4.367 0.148 -1.285 -1.378 ... #>  $ se.fit: Named num [1:450] 0.533 0.531 0.609 0.536 0.539 ... #>   ..- attr(*, \"names\")= chr [1:450] \"1\" \"2\" \"3\" \"4\" ... str(predict(mcre,type=\"response\",se.fit=TRUE)) #> List of 2 #>  $ fit   : num [1:450] 0.03789 0.92862 0.01366 0.00326 0.00297 ... #>  $ se.fit: num [1:450] 0.004138 0.007417 0.004969 0.000562 0.000509 ..."},{"path":"https://melff.github.io/mclogit/reference/rebase.html","id":null,"dir":"Reference","previous_headings":"","what":"Change baseline category of multinomial logit or similar model — rebase","title":"Change baseline category of multinomial logit or similar model — rebase","text":"`rebase` returns model object equivalent one given argument differs parameterization","code":""},{"path":"https://melff.github.io/mclogit/reference/rebase.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change baseline category of multinomial logit or similar model — rebase","text":"","code":"rebase(object, to, ...)  # S3 method for class 'mblogit' rebase(object, to, ...)"},{"path":"https://melff.github.io/mclogit/reference/rebase.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change baseline category of multinomial logit or similar model — rebase","text":"object statistical model object usually, string; baseline category ... arguments, currently ignored","code":""},{"path":"https://melff.github.io/mclogit/reference/simulate.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulating responses from baseline-category and conditional logit models — simulate.mclogit","title":"Simulating responses from baseline-category and conditional logit models — simulate.mclogit","text":"simulate() methods allow simulate responses models   fitted mclogit() mblogit(). Currently   models without random effects supported .","code":""},{"path":"https://melff.github.io/mclogit/reference/simulate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulating responses from baseline-category and conditional logit models — simulate.mclogit","text":"","code":"# S3 method for class 'mblogit' simulate(object, nsim = 1, seed = NULL, ...) # S3 method for class 'mclogit' simulate(object, nsim = 1, seed = NULL, ...)  # These methods are currently just 'stubs', causing an error # message stating that simulation from models with random # effects are not supported yet # S3 method for class 'mmblogit' simulate(object, nsim = 1, seed = NULL, ...) # S3 method for class 'mmclogit' simulate(object, nsim = 1, seed = NULL, ...)"},{"path":"https://melff.github.io/mclogit/reference/simulate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulating responses from baseline-category and conditional logit models — simulate.mclogit","text":"object object relevant class nsim number, specifying number simulated responses     observation. seed object specifying random number     generator initialized ('seeded'). interpetation   argument follows default method, see link[stats]{simulate} ... arguments, ignored.","code":""},{"path":"https://melff.github.io/mclogit/reference/simulate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulating responses from baseline-category and conditional logit models — simulate.mclogit","text":"result simulate method objects   created mclogit data frame one variable   requested simulation run (number given   nsim= argument). contents columns counts (  zero-one values), group-wise multinomial distribution (within   choice sets) just like assumed original response. shape result simulate method   objects created mblogit also data frame.   variables within data frame mode shape   corresponds response model fitted.   response matrix counts, variables data frame   also matrices counts.  response factor   mblogit called argument   .table=FALSE, variables data frame factors   factor levels response model   fitted. instead function called   .table=TRUE, variables data frame counts,   represent frequency weights result applying   .data.frame contingency table simulated   frequency counts.","code":""},{"path":"https://melff.github.io/mclogit/reference/simulate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulating responses from baseline-category and conditional logit models — simulate.mclogit","text":"","code":"library(MASS) (house.mblogit <- mblogit(Sat ~ Infl + Type + Cont,                            data = housing,                           weights=Freq,                           aggregate=TRUE)) #>  #> Iteration 1 - deviance = 38.84842 - criterion = 0.992521 #> Iteration 2 - deviance = 38.66222 - criterion = 0.004803721 #> Iteration 3 - deviance = 38.6622 - criterion = 3.782555e-07 #> Iteration 4 - deviance = 38.6622 - criterion = 3.666163e-15 #> converged #>  #> Call: mblogit(formula = Sat ~ Infl + Type + Cont, data = housing, weights = Freq,  #>     aggregate = TRUE) #>  #> Coefficients: #>             Predictors #> Logit eqn.    (Intercept)  InflMedium  InflHigh  TypeApartment  TypeAtrium #>   Medium/Low  -0.4192       0.4464      0.6649   -0.4357         0.1314    #>   High/Low    -0.1387       0.7349      1.6126   -0.7356        -0.4080    #>             Predictors #> Logit eqn.    TypeTerrace  ContHigh #>   Medium/Low  -0.6666       0.3609  #>   High/Low    -1.4123       0.4818  #>  #> Null Deviance:     262.1  #> Residual Deviance: 38.66 sm <- simulate(house.mblogit,nsim=7)  housing.long <- housing[rep(seq.int(nrow(housing)),housing$Freq),] (housel.mblogit <- mblogit(Sat ~ Infl + Type + Cont,                            data=housing.long)) #>  #> Iteration 1 - deviance = 3474.691 - criterion = 0.5057269 #> Iteration 2 - deviance = 3470.086 - criterion = 0.001326883 #> Iteration 3 - deviance = 3470.084 - criterion = 7.526912e-07 #> Iteration 4 - deviance = 3470.084 - criterion = 1.308345e-12 #> converged #>  #> Call: mblogit(formula = Sat ~ Infl + Type + Cont, data = housing.long) #>  #> Coefficients: #>             Predictors #> Logit eqn.    (Intercept)  InflMedium  InflHigh  TypeApartment  TypeAtrium #>   Medium/Low  -0.4192       0.4464      0.6649   -0.4357         0.1314    #>   High/Low    -0.1387       0.7349      1.6126   -0.7356        -0.4080    #>             Predictors #> Logit eqn.    TypeTerrace  ContHigh #>   Medium/Low  -0.6666       0.3609  #>   High/Low    -1.4123       0.4818  #>  #> Null Deviance:     3694  #> Residual Deviance: 3470 sml <- simulate(housel.mblogit,nsim=7)  housing.table <- xtabs(Freq~.,data=housing) housing.mat <- memisc::to.data.frame(housing.table) head(housing.mat) #>     Infl      Type Cont Low Medium High #> 1    Low     Tower  Low  21     21   28 #> 2 Medium     Tower  Low  34     22   36 #> 3   High     Tower  Low  10     11   36 #> 4    Low Apartment  Low  61     23   17 #> 5 Medium Apartment  Low  43     35   40 #> 6   High Apartment  Low  26     18   54  (housem.mblogit <- mblogit(cbind(Low,Medium,High) ~                                Infl + Type + Cont,                            data=housing.mat)) #>  #> Iteration 1 - deviance = 38.84842 - criterion = 0.992521 #> Iteration 2 - deviance = 38.66222 - criterion = 0.004803721 #> Iteration 3 - deviance = 38.6622 - criterion = 3.782555e-07 #> Iteration 4 - deviance = 38.6622 - criterion = 3.666163e-15 #> converged #>  #> Call: mblogit(formula = cbind(Low, Medium, High) ~ Infl + Type + Cont,  #>     data = housing.mat) #>  #> Coefficients: #>             Predictors #> Logit eqn.    (Intercept)  InflMedium  InflHigh  TypeApartment  TypeAtrium #>   Medium/Low  -0.4192       0.4464      0.6649   -0.4357         0.1314    #>   High/Low    -0.1387       0.7349      1.6126   -0.7356        -0.4080    #>             Predictors #> Logit eqn.    TypeTerrace  ContHigh #>   Medium/Low  -0.6666       0.3609  #>   High/Low    -1.4123       0.4818  #>  #> Null Deviance:     262.1  #> Residual Deviance: 38.66 smm <- simulate(housem.mblogit,nsim=7)  str(sm) #> 'data.frame':\t0 obs. of  7 variables: #>  $ sim_1: int  #>  $ sim_2: int  #>  $ sim_3: int  #>  $ sim_4: int  #>  $ sim_5: int  #>  $ sim_6: int  #>  $ sim_7: int  #>  - attr(*, \"seed\")= int [1:626] 10403 207 1980538363 -125047968 -820381145 -1073960099 -33499050 1164085917 1218464490 -1045685882 ... str(sml) #> 'data.frame':\t1681 obs. of  7 variables: #>  $ sim_1: Factor w/ 3 levels \"Low\",\"Medium\",..: 2 3 3 3 3 1 3 1 1 1 ... #>  $ sim_2: Factor w/ 3 levels \"Low\",\"Medium\",..: 1 3 1 1 1 2 1 1 1 2 ... #>  $ sim_3: Factor w/ 3 levels \"Low\",\"Medium\",..: 1 1 2 1 3 2 3 2 3 1 ... #>  $ sim_4: Factor w/ 3 levels \"Low\",\"Medium\",..: 1 2 2 2 3 2 3 3 1 3 ... #>  $ sim_5: Factor w/ 3 levels \"Low\",\"Medium\",..: 1 3 1 2 1 1 3 3 1 2 ... #>  $ sim_6: Factor w/ 3 levels \"Low\",\"Medium\",..: 2 2 1 3 3 3 3 1 1 3 ... #>  $ sim_7: Factor w/ 3 levels \"Low\",\"Medium\",..: 2 1 3 1 1 3 2 2 2 3 ... #>  - attr(*, \"seed\")= int [1:626] 10403 19 1492790388 -1629574902 -1817687082 -2080485428 -622102478 -1390801052 -1280540579 249411485 ... str(smm) #> 'data.frame':\t24 obs. of  7 variables: #>  $ sim_1: int [1:24, 1:3] 26 23 2 53 45 20 15 5 3 22 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:3] \"Low\" \"Medium\" \"High\" #>  $ sim_2: int [1:24, 1:3] 30 24 10 55 41 25 19 9 3 17 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:3] \"Low\" \"Medium\" \"High\" #>  $ sim_3: int [1:24, 1:3] 23 25 10 54 46 32 13 8 7 22 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:3] \"Low\" \"Medium\" \"High\" #>  $ sim_4: int [1:24, 1:3] 22 30 9 52 46 32 13 9 3 15 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:3] \"Low\" \"Medium\" \"High\" #>  $ sim_5: int [1:24, 1:3] 22 23 3 57 45 27 8 11 4 21 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:3] \"Low\" \"Medium\" \"High\" #>  $ sim_6: int [1:24, 1:3] 24 22 8 49 36 29 14 10 5 19 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:3] \"Low\" \"Medium\" \"High\" #>  $ sim_7: int [1:24, 1:3] 35 25 16 53 43 23 18 9 5 20 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:3] \"Low\" \"Medium\" \"High\" #>  - attr(*, \"seed\")= int [1:626] 10403 554 1019603289 -1305277535 -470137223 -57077173 1775921955 -181041711 861366705 -1087987206 ...  head(smm[[1]]) #>      Low Medium High #> [1,]  26     17   27 #> [2,]  23     28   41 #> [3,]   2      7   48 #> [4,]  53     20   28 #> [5,]  45     36   37 #> [6,]  20     22   56"}]
